{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Internal Linear Combination (ILC) applied to wavelet coefficient maps across all frequency channels at each scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import s2fft\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import s2wav\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create the directory structure to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_and_create_ilc_directories():\n",
    "    \"\"\"\n",
    "    Checks for the existence of a specific nested directory structure for ILC processing and creates any missing directories.\n",
    "    This includes handling multiple levels of nested directories as shown in the provided folder structure.\n",
    "\n",
    "    The structure checked is:\n",
    "    - ILC\n",
    "      - covariance_matrix\n",
    "      - ILC_doubled_maps\n",
    "      - ILC_processed_wavelet_maps\n",
    "      - synthesized_ILC_MW_maps\n",
    "      - wavelet_doubled\n",
    "      - weight_vector_data\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the root directories\n",
    "    # base_dir = \"path_to_base_directory\"  # Set this to your base directory path\n",
    "    # ilc_dir = os.path.join(base_dir, \"ILC\")\n",
    "    ilc_dir = \"ILC\"\n",
    "    # List of directories under the ILC directory\n",
    "    ilc_sub_dirs = [\"covariance_matrix\", \"ILC_doubled_maps\", \"ILC_processed_wavelet_maps\", \"synthesized_ILC_MW_maps\",\"wavelet_doubled\",\"weight_vector_data\"]\n",
    "\n",
    "    # Create the ILC directory and its subdirectories\n",
    "    create_directory(ilc_dir)\n",
    "    for sub_dir in ilc_sub_dirs:\n",
    "        create_directory(os.path.join(ilc_dir, sub_dir))\n",
    "\n",
    "def create_directory(dir_path):\n",
    "    \"\"\"\n",
    "    Checks if a directory exists, and if not, creates it. Prints the status of the directory.\n",
    "    \n",
    "    Parameters:\n",
    "        dir_path (str): The path of the directory to check and create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(f\"Created directory: {dir_path}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {dir_path}\")\n",
    "\n",
    "# Run the function to check and create directories as needed\n",
    "check_and_create_ilc_directories()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ILC Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mw_alm_2_hp_alm(MW_alm, lmax):\n",
    "    '''\n",
    "    Converts MW alm coefficients to HEALPix alm coefficients.\n",
    "    \n",
    "    Arg:\n",
    "        MW_alm: 2D array of shape (Lmax, 2*Lmax-1) (MW sampling, McEwen & Wiaux)\n",
    "        lmax: maximum multipole moment of the MW alm\n",
    "    Returns:\n",
    "        hp_alm: 1D array in healpix \n",
    "    '''\n",
    "    # Initialize the 1D hp_alm array with the appropriate size\n",
    "    hp_alm = np.zeros(hp.Alm.getsize(lmax), dtype=np.complex128)\n",
    "        \n",
    "    for l in range(lmax + 1):\n",
    "        for m in range(-l, l + 1):\n",
    "            index = hp.Alm.getidx(lmax, l, abs(m))\n",
    "            if m < 0:\n",
    "                hp_alm[index] = (-1)**m * np.conj(MW_alm[l, lmax + m])\n",
    "            else:\n",
    "                hp_alm[index] = MW_alm[l, lmax + m]\n",
    "\n",
    "    return hp_alm\n",
    "\n",
    "def visualize_wavelet_coefficient_map(MW_Pix_Map, title, variable, min=None, max=None):\n",
    "    \"\"\"\n",
    "    Processes a wavelet coefficient map and visualizes it using HEALPix mollview.\n",
    "\n",
    "    Parameters:\n",
    "       MW_Pix_map: the MW wavelet coefficient map. (MW sampling, McEwen & Wiaux)\n",
    "       title (str): the title for the plot.\n",
    "    Returns:\n",
    "        Displays a mollview map.\n",
    "    \"\"\"\n",
    "    \n",
    "    if MW_Pix_Map.shape[0] != 1:\n",
    "        L_max = MW_Pix_Map.shape[0]\n",
    "    else:\n",
    "        # 3 dimensions MW_Pix_Map (product of s2wav.analysis)\n",
    "        L_max = MW_Pix_Map.shape[1]\n",
    "\n",
    "    original_map_alm = s2fft.forward(MW_Pix_Map, L=L_max)\n",
    "    # print(\"Original map alm shape:\", original_map_alm.shape)\n",
    "    \n",
    "    original_map_hp_alm = mw_alm_2_hp_alm(original_map_alm, L_max - 1)\n",
    "    original_hp_map = hp.alm2map(original_map_hp_alm, nside=(L_max - 1)//2)\n",
    "\n",
    "    hp.mollview(\n",
    "        # original_hp_map * 1e5,\n",
    "        original_hp_map,\n",
    "        coord=[\"G\"],\n",
    "        title=title+variable,\n",
    "        unit=r\"K\",\n",
    "        # min=min, max=max,  # Uncomment and adjust these as necessary for better visualization contrast\n",
    "    )\n",
    "    return original_hp_map\n",
    "\n",
    "def Single_Map_doubleworker(MW_Pix_Map):\n",
    "    '''\n",
    "    Arg:\n",
    "        MW_Pix_Map: a MW wavelet coefficent pixel map of shape (1, Lmax, 2*Lmax-1) (MW sampling, McEwen & Wiaux)\n",
    "        It is the output of s2wav.analysis\n",
    "        (Scale: 0, size (1, 4, 7))\n",
    "\n",
    "    Process:\n",
    "        1. Covert MW Pixel Map to MW alm space using s2fft.forward\n",
    "\n",
    "        2. Double alm: Add zero to the mw alms  \n",
    "        \n",
    "        3. Convert doubled mw alm to mw map \n",
    "\n",
    "    Returns:\n",
    "        MW_Pix_Map_doubled: The MW pixel map with increased resolution.\n",
    "    \n",
    "    '''\n",
    "    MW_alm = s2fft.forward(MW_Pix_Map, L = MW_Pix_Map.shape[1])\n",
    "    L = MW_alm.shape[0]\n",
    "    padded_alm = np.zeros((2*L-1,2*(2*L-1)-1),dtype=np.complex128)\n",
    "    # L = 4 | l = 0,1,2,3 , true lmax is L-1 = 3 | m = -3...0...(L-1)| m = 2(L-1)+1 = 2L-1      \n",
    "    # double true lmax: 2*3 = 6, and add 1, new L = 7 = 2(L-1)+1 = 2L-1\n",
    "    # new m = -6...0...(new L-1) | new m = 2*(2L-1)-1\n",
    "    inner_matrix_middle = MW_alm.shape[1] // 2\n",
    "    outer_matrix_middle = padded_alm.shape[1] // 2\n",
    "    start_col = (outer_matrix_middle - inner_matrix_middle)\n",
    "    end_col = start_col + MW_alm.shape[1] # not included\n",
    "      \n",
    "    padded_alm[:MW_alm.shape[0], start_col:end_col] = MW_alm\n",
    "    # print(padded_alm[:MW_alm.shape[0], start_col:start_col + end_col].shape)\n",
    "    # print(\"padded alm size\", padded_alm)\n",
    "    # print(padded_alm.shape)\n",
    "    \n",
    "    MW_Pix_Map_doubled = np.real(s2fft.inverse(padded_alm, L = padded_alm.shape[0]))\n",
    "    # print(\"Scale:\",\"doubled map size\", MW_Pix_Map_doubled.shape)\n",
    "    # Note\n",
    "    # assert imaginery part is around zero\n",
    "    # print(np.imag(MW_Pix_Map_doubled))\n",
    "    # MW_Pix_Map_doubled = s2fft.inverse(MW_alm_doubled, L = MW_alm_doubled.shape[0])\n",
    "    \n",
    "    return MW_Pix_Map_doubled\n",
    "\n",
    "def smoothed_covariance(MW_Map1, MW_Map2):\n",
    "    '''\n",
    "    Args:\n",
    "        MW_Map1, MW_Map2: same size MW pixel wavelet maps at different frequencies\n",
    "    Returns:\n",
    "        R_map: smoothed covariance map beteen MW_Map1 and MW_Map2\n",
    "    '''\n",
    "    smoothing_lmax = MW_Map1.shape[0]\n",
    "    # Get the real part of the map\n",
    "    map1 = np.real(MW_Map1)\n",
    "    map2 = np.real(MW_Map2)\n",
    "    # Covariance matrix\n",
    "    R_MW_Pixel_map = np.multiply(map1,map2) + 0.j #Add back in zero imaginary part\n",
    "\n",
    "    # smoothing in harmonic space for efficiency\n",
    "    R_MW_alm = s2fft.forward(R_MW_Pixel_map, L = smoothing_lmax)\n",
    "\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = R_MW_alm.shape[0]\n",
    "    npix = hp.nside2npix(1<<(int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    # (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "    # 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    # for high resolution maps, it is still the same number pixels sampled by the actual range is smaller.\n",
    "    # the beam will become very narrow.\n",
    "\n",
    "    gauss_smooth = hp.gauss_beam(scale_fwhm,lmax=smoothing_lmax-1)\n",
    "    MW_alm_beam_convolved = np.zeros(R_MW_alm.shape, dtype=np.complex128)\n",
    "\n",
    "    # Convolve the MW alms with the beam\n",
    "    for i in range(R_MW_alm.shape[1]):\n",
    "        MW_alm_beam_convolved[:, i] = R_MW_alm[:, i] * gauss_smooth\n",
    "    \n",
    "    R_covariance_map = np.real(s2fft.inverse(MW_alm_beam_convolved, L = smoothing_lmax))\n",
    "\n",
    "    return R_covariance_map\n",
    "\n",
    "def load_frequency_data(base_path, file_template, frequencies, scales=None, realization = None):\n",
    "    \"\"\"\n",
    "    Load NumPy arrays from dynamically generated file paths for each frequency and scale.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): The base path where the files are located.\n",
    "        file_template (str): The template for the file names, with placeholders for frequency and scale.\n",
    "        frequencies (list): A list of frequency names.\n",
    "        scales_: A lists of scales.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are tuples of (frequency, scale) and values are loaded NumPy arrays.\n",
    "    \"\"\"\n",
    "    frequency_data = {}\n",
    "    realization = str(realization).zfill(4)\n",
    "    for frequency in frequencies:\n",
    "        for scale in scales:\n",
    "            # Generate the file path using the template and the current frequency and scale\n",
    "            path = f\"{base_path}/{file_template.format(frequency, scale, realization)}\"\n",
    "            try:\n",
    "                frequency_data[(frequency, scale)] = np.load(path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {path} for frequency {frequency} and scale {scale}: {e}, realization {realization}\")\n",
    "    return frequency_data\n",
    "\n",
    "def double_and_save_wavelet_maps(original_wavelet_c_j, frequencies, scales, realization):\n",
    "    \"\"\"\n",
    "    Doubles the resolution of wavelet maps and saves them with the realization number in the file name.\n",
    "\n",
    "    Args:\n",
    "        original_wavelet_c_j (dict): Dictionary containing the original wavelet maps.\n",
    "        frequencies (list): List of frequency strings.\n",
    "        scales (list): List of scale indices.\n",
    "        realization (int): The realization number for file naming.\n",
    "    \"\"\"\n",
    "    for i in frequencies:\n",
    "        for j in scales:\n",
    "            # Perform the doubling of the wavelet map for the given frequency and scale\n",
    "            wavelet_MW_Pix_Map_doubled = Single_Map_doubleworker(original_wavelet_c_j[(i, j)])\n",
    "            \n",
    "            # Save the doubled wavelet map with the realization number in the filename\n",
    "            # np.save(f\"ILC/wavelet_doubled/Wav_Pix2_F{i}_S{j}_R{realization:04d}.npy\", wavelet_MW_Pix_Map_doubled)\n",
    "            np.save(f\"ILC/wavelet_doubled/Wav_Pix2_F{i}_S{j}_R{realization}.npy\", wavelet_MW_Pix_Map_doubled)\n",
    "\n",
    "def calculate_covariance_matrix(frequencies, doubled_MW_wav_c_j, scale, realization):\n",
    "    \"\"\"\n",
    "    Calculates the covariance matrices for given frequencies and saves them to disk,\n",
    "    accommodating any size of the input data arrays.\n",
    "    \n",
    "    Args:\n",
    "        frequencies (list): List of frequency indices.\n",
    "        doubled_MW_wav_c_j (dict): Dictionary containing data arrays for covariance calculations.\n",
    "        scale (int): The scale.\n",
    "        realization (int): The realization.\n",
    "\n",
    "    Returns:\n",
    "        full_array: np.ndarray: A 4D array containing the covariance matrices for the given frequencies.\n",
    "    \"\"\"\n",
    "    # Check dimensions of the first item to set the size of the covariance matrices\n",
    "    if frequencies:\n",
    "        sample_data = doubled_MW_wav_c_j[(frequencies[0], scale)]\n",
    "        n_rows, n_cols = sample_data.shape\n",
    "    else:\n",
    "        raise ValueError(\"Frequency list is empty.\")\n",
    "    \n",
    "    total_frequency = len(frequencies)\n",
    "    # Initialize a 4D array to store the covariance matrices\n",
    "    full_array = np.zeros((total_frequency, total_frequency, n_rows, n_cols))\n",
    "\n",
    "    # Calculate the covariance matrix and save each one\n",
    "    # Calculate the upper triangle only since the matrix is symmetric\n",
    "    for i in range(total_frequency):\n",
    "        for fq in range(i, total_frequency):\n",
    "            # print(f\"Calculating covariance between {frequencies[i]} and {frequencies[fq]}\")\n",
    "            \n",
    "            full_array[i, fq] = smoothed_covariance(doubled_MW_wav_c_j[(frequencies[i], scale)],\n",
    "                                                    doubled_MW_wav_c_j[(frequencies[fq], scale)])\n",
    "            # Save the computed covariance matrix\n",
    "            # np.save(f\"ILC/covariance_matrix/cov_MW_Pix2_F{frequencies[i]}_F{frequencies[fq]}_S{scale}\", full_array[i, fq])\n",
    "    f = '_'.join(frequencies)\n",
    "    \n",
    "    # Testing if single process output is the same as multiprocessing output\n",
    "    # np.save(f\"ILC/covariance_matrix/half_original_{scale}_R{realization}\", full_array)\n",
    "    # Fill the symmetric part of the matrix\n",
    "    for l1 in range(1, total_frequency):\n",
    "        for l2 in range(l1):\n",
    "            full_array[l1, l2] = full_array[l2, l1]\n",
    "    np.save(f\"ILC/covariance_matrix/cov_MW_Pix2_F{f}_S{scale}_R{realization}_Full\", full_array)\n",
    "    # print(full_array.shape)\n",
    "    return full_array\n",
    "\n",
    "def compute_weight_vector(R,scale,realization):\n",
    "    \"\"\"\n",
    "    Processes the given 4D matrix R by computing and saving the weight vectors for each matrix in the first two dimensions.\n",
    "    Also stores results in memory as arrays and saves them to disk. Adjusts the size of the identity vector based on sub-matrix size.\n",
    "\n",
    "    Args:\n",
    "        R (np.ndarray): A 4D matrix with dimensions suitable for swapping and inverting.\n",
    "        scale (int): The scale.\n",
    "        realization (int): The realization.\n",
    "    Returns:\n",
    "        inverses: (np.ndarray): An Array containing the inverse matrices\n",
    "        weight_vectors (np.ndarray): A 3D Array containing the weight vector.\n",
    "        The size of the first two dimensions of the weight vector is the size of the wavelet coefficient map at the given scale.\n",
    "        The third dimension is the weight vector (The contribution from each frequency).\n",
    "        Each element of the weight vector is a 1D array.\n",
    "        singular_matrices_location (list): The locations of singular matrices.\n",
    "    \"\"\"\n",
    "    # print(R.shape)\n",
    "    # Swap the axes to get R_Pix\n",
    "    R_Pix = np.swapaxes(np.swapaxes(R, 0, 2), 1, 3)\n",
    "    \n",
    "    # Get dimensions for looping and size of sub-matrices\n",
    "    dim1, dim2, subdim1, subdim2 = R_Pix.shape\n",
    "    # print(dim1, dim2, subdim1, subdim2)\n",
    "    # Create arrays to store inverses and weight vectors\n",
    "    inverses = np.zeros((dim1, dim2, subdim1, subdim2))\n",
    "    weight_vectors = np.zeros((dim1, dim2, subdim1))\n",
    "\n",
    "    # Realiztion 6 has a singular matrix\n",
    "    # Adjust identity vector size based on sub-matrix dimensions\n",
    "    identity_vector = np.ones(subdim2, dtype=float)\n",
    "    singular_matrices_lcoation = []\n",
    "    singular_matrices = []\n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            \n",
    "            det = np.linalg.det(R_Pix[i, j])\n",
    "            if det == 0:\n",
    "                print(i,j)\n",
    "                print(R_Pix[i, j].shape)\n",
    "                print(det)\n",
    "                print(R_Pix[i, j])\n",
    "                print(\"Pixel\", i,j)\n",
    "                print(\"The matrix is singular.\")\n",
    "                # np.linalg.inv(R_Pix[i, j])\n",
    "                zeros = np.zeros((subdim1))\n",
    "\n",
    "                singular_matrices_lcoation.append((i,j))\n",
    "                singular_matrices.append(R_Pix[i, j])\n",
    "                weight_vectors[i, j] = zeros\n",
    "                np.save(f\"ILC/weight_vector_data/inverse_singular_matrix_{i}_{j}_S{scale}_R{realization}.npy\", R_Pix[i,j])\n",
    "                print(\"saved at \", f\"ILC/weight_vector_data/inverse_singular_matrix_{i}_{j}_S{scale}_R{realization}.npy\")\n",
    "                \n",
    "            else:\n",
    "                # print(\"The matrix is not singular.\")\n",
    "                # Invert the matrix at position (i, j)\n",
    "                inverses[i, j] = np.linalg.inv(R_Pix[i, j])\n",
    "            \n",
    "                # Compute the weight vector\n",
    "                numerator = np.dot(inverses[i, j], identity_vector)\n",
    "                denominator = np.dot(np.dot(inverses[i, j], identity_vector),identity_vector)\n",
    "                weight_vectors[i, j] = numerator / denominator\n",
    "        \n",
    "            # Save the inverse matrix and weight vector to disk\n",
    "            # np.save(f\"../weight_vector_data/inverse_matrix_{i}_{j}.npy\", inverses[i, j])\n",
    "            # np.save(f\"../weight_vector_data/weight_vector_{i}_{j}.npy\", weight_vectors[i, j])\n",
    "\n",
    "    np.save(f\"ILC/weight_vector_data/weight_vector_S{scale}_R{realization}\", weight_vectors)\n",
    "            \n",
    "\n",
    "    return inverses, weight_vectors,singular_matrices_lcoation,singular_matrices\n",
    " \n",
    "def compute_ILC_for_pixel(i, j, frequencies, scale, weight_vector_load, doubled_MW_wav_c_j):\n",
    "    \"\"\"\n",
    "    Computes the Internal Linear Combination (ILC) value for a specific pixel using the provided wavelet coefficients and weight vectors.\n",
    "\n",
    "    Args:\n",
    "        i (int): The row index of the pixel in the map.\n",
    "        j (int): The column index of the pixel in the map.\n",
    "        frequencies (list): A list of frequency identifiers corresponding to different channels.\n",
    "        scale (int): The scale of the wavelet coefficient map.\n",
    "        weight_vector_load (list): A list where each element corresponds to the weight vector map at a scale.\n",
    "        doubled_MW_wav_c_j (dict): A dictionary with keys as tuples of (frequency, scale) and values as 2D arrays of wavelet coefficients for each pixel.\n",
    "\n",
    "    Returns:\n",
    "        float: The ILC value computed for the pixel at position (i, j).\n",
    "    \"\"\"\n",
    "    # Create a vector of pixel values of all frequencies at the given pixel position\n",
    "    pix_vector = np.array([\n",
    "        doubled_MW_wav_c_j[(frequencies[k], scale)][i, j] for k in range(len(frequencies))\n",
    "    ])\n",
    "    return np.dot(weight_vector_load[scale][i, j], pix_vector)\n",
    "\n",
    "def create_doubled_ILC_map(frequencies, scale, weight_vector_load, doubled_MW_wav_c_j, realization):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a doubled Internal Linear Combination (ILC) map for a given scale and realization.\n",
    "    Doubled because the resolution of the wavelet coefficient map is doubled.\n",
    "    \n",
    "    Args:\n",
    "        frequencies (list): A list of frequency identifiers corresponding to different channels.\n",
    "        scale (int): The wavelet coefficient scale.\n",
    "        weight_vector_load (list): A list where each element corresponds to the weight vector map at a scale.\n",
    "        doubled_MW_wav_c_j (dict): A dictionary with keys as tuples of (frequency, scale) and values as 2D arrays of wavelet coefficients for each pixel.\n",
    "        realization (int): The realization index used for saving the resulting ILC map.\n",
    "\n",
    "    Returns:\n",
    "        doubled_map (np.ndarray): The generated ILC map as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    # Get the size of the wavelet map\n",
    "    size = doubled_MW_wav_c_j[(frequencies[0],scale)].shape\n",
    "    \n",
    "    # Initialize the doubled map\n",
    "    doubled_map = np.zeros((size[0], size[1]))\n",
    "    \n",
    "    # Compute the ILC value for each pixel in the map\n",
    "    for i in range(doubled_map.shape[0]):\n",
    "        for j in range(doubled_map.shape[1]):\n",
    "            doubled_map[i, j] = compute_ILC_for_pixel(i, j, frequencies, scale,weight_vector_load, doubled_MW_wav_c_j)\n",
    "    np.save(f\"ILC/ILC_doubled_maps/ILC_Map_S{scale}_R{realization}\", doubled_map)\n",
    "    \n",
    "    return doubled_map\n",
    "\n",
    "def trim_to_original(MW_Doubled_Map, scale, realization):\n",
    "    '''\n",
    "    Input:\n",
    "        MW_Doubled_Map: The MW Pixel map with increased resolution.\n",
    "        original_shape: A tuple indicating the original size of the alm data.\n",
    "\n",
    "    Process:\n",
    "        1. convet it to alm  \n",
    "        1. Trim the alm back to its original dimensions.\n",
    "        2. Convert the trimmed alm array back to a pixel map using an inverse spherical transform.\n",
    "\n",
    "    Returns:\n",
    "        MW_Pix_Map_original: The pixel map converted back to its original resolution.\n",
    "    '''\n",
    "\n",
    "    # 8,15, 15//2 = 7\n",
    "    MW_alm_doubled = s2fft.forward(MW_Doubled_Map, L=MW_Doubled_Map.shape[0])\n",
    "    # print(MW_alm_doubled)\n",
    "    inner_matrix_vertical = int((MW_Doubled_Map.shape[0]+1) / 2)\n",
    "    inner_matrix_horizontal = int(2*inner_matrix_vertical - 1)\n",
    "    \n",
    "    inner_matrix_middle = inner_matrix_horizontal // 2\n",
    "    outer_matrix_middle = MW_Doubled_Map.shape[1] // 2\n",
    "    start_col = (outer_matrix_middle - inner_matrix_middle)\n",
    "    end_col = start_col + inner_matrix_horizontal # not included\n",
    "\n",
    "    # Extract the original size part from the doubled alm data\n",
    "    trimmed_alm = MW_alm_doubled[:inner_matrix_vertical, start_col:end_col]\n",
    "    print(\"trimmed alm shape\", trimmed_alm.shape)\n",
    "    # Convert trimmed alm to the original pixel map\n",
    "    MW_Pix_Map_original = s2fft.inverse(trimmed_alm, L=trimmed_alm.shape[0])[np.newaxis, ...]\n",
    "    np.save(f\"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S{scale}_R{realization}\", MW_Pix_Map_original)\n",
    "    return MW_Pix_Map_original\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Combine all the steps for Internal Linear Combination together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wavelet_maps(base_path, file_template, frequencies, scales, realizations):\n",
    "    for realization in realizations:\n",
    "        realization_str = str(realization).zfill(4)\n",
    "        print(f\"Processing realization {realization_str}\")\n",
    "        path = f\"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S5_R{realization_str}.npy\"\n",
    "        if os.path.exists(path):\n",
    "                print(f\"File {path} already exists.\")\n",
    "                continue\n",
    "        original_wavelet_c_j = load_frequency_data(base_path, file_template, frequencies, scales, realization_str)\n",
    "\n",
    "        # Double the resolution of the wavelet maps\n",
    "        double_and_save_wavelet_maps(original_wavelet_c_j, frequencies, scales, realization_str)\n",
    "\n",
    "        doubled_MW_wav_c_j = load_frequency_data(\"ILC/wavelet_doubled/\", \"Wav_Pix2_F{}_S{}_R{}.npy\", frequencies, scales, realization_str)\n",
    "\n",
    "        # Calculate the covariance matrices for each scale\n",
    "        for i in range(len(scales)):      \n",
    "            scale = i\n",
    "            # print(\"Calculate covariance for Scale\", i)\n",
    "            calculate_covariance_matrix(frequencies, doubled_MW_wav_c_j, scale, realization_str)\n",
    "\n",
    "        F_str = '_'.join(frequencies)\n",
    "        R_covariance = [np.load(f\"ILC/covariance_matrix/cov_MW_Pix2_F{F_str}_S{i}_R{realization_str}_Full.npy\") for i in range(len(scales))]\n",
    "        # print(len(R_covariance))\n",
    "        # print(R_covariance[0].shape)  \n",
    "\n",
    "        # Calculate the weight vectors for each frequency wavelet coefficient map using covariance matrix and the euqation.\n",
    "        for scale in range(len(R_covariance)):\n",
    "            # print(scale)\n",
    "            compute_weight_vector(R_covariance[scale], scale, realization_str)\n",
    "            \n",
    "        weight_vector_load = [np.load(f\"ILC/weight_vector_data/weight_vector_S{i}_R{realization_str}.npy\") for i in range(len(scales))]\n",
    "\n",
    "        doubled_maps = []\n",
    "\n",
    "        # Create the doubled resolution ILC map for each scale\n",
    "        for i in range(len(scales)):\n",
    "            doubled_maps.append(create_doubled_ILC_map(frequencies, scales[i], weight_vector_load, doubled_MW_wav_c_j, realization=realization_str))\n",
    "\n",
    "        doubled_maps = [np.load(f\"ILC/ILC_doubled_maps/ILC_Map_S{i}_R{realization_str}.npy\") for i in range(len(scales))]\n",
    "\n",
    "        # Trim the doubled resolution ILC map back to the original resolution\n",
    "        trimmed_maps = [trim_to_original(doubled_maps[i], i, realization_str) for i in range(len(scales))]\n",
    "        \n",
    "        for i in range(len(scales)):\n",
    "            tilte = \"wavelet coefficient map at scale: \"\n",
    "            visualize_wavelet_coefficient_map(trimmed_maps[i], tilte, str(i))\n",
    "        return trimmed_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path, file template, frequencies, scales, and realizations\n",
    "# Base path for the generated wavelet coefficient maps\n",
    "base_path = \"wavelet_transform/wavelets/wav_MW_maps\"\n",
    "\n",
    "# File template for the wavelet coefficient maps\n",
    "file_template = \"Wav_MW_Pix_F{}_S{}_R{}.npy\"\n",
    "\n",
    "frequencies = ['030', '044', '070', '100', '143', '217', '353', '545', '857']\n",
    "# scale is based on the number of wavelet coefficient map generated by s2wav.analysis\n",
    "scales = [0, 1, 2, 3, 4, 5, 6, 7, 8] \n",
    "# realizations = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "realizations = [0]\n",
    "\n",
    "process_wavelet_maps(base_path, file_template, frequencies, scales, realizations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Visualize ILC combined Wavelet coefficient maps for each scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L max for the wavelet coefficient map\n",
    "L_max = 32\n",
    "N_directions = 1\n",
    "for i in range(1):\n",
    "    realization = str(realizations[i]).zfill(4)\n",
    "    trimmed_maps = [np.load(f\"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S{i}_R{realization}.npy\") for i in range(len(scales))]\n",
    "    for j in range(len(scales)):\n",
    "            visualize_wavelet_coefficient_map(trimmed_maps[j], \"ILC wavelet coefficient map at scale: \", str(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Synthesize ILC wavelet coefficient maps of all scales together. \n",
    "Note: Unfinished task for handling scaling coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s2wav\n",
    "from s2wav import filters\n",
    "L_max = 32\n",
    "N_directions = 1\n",
    "for i in range(len(realizations)):\n",
    "    realization = str(realizations[i]).zfill(4)\n",
    "    ILC_trimmed_wav_maps = [np.load(f\"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S{scale}_R{realization}.npy\") for scale in range(len(scales))]\n",
    "\n",
    "    filter = filters.filters_directional_vectorised(L_max, N_directions)\n",
    "    # f_scal = np.array([[0]]) #np.load(f\"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_F030.npy\") \n",
    "    f_scal = np.array([[0]])    \n",
    "    # [np.load(f\"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_F{frequencies[i]}.npy\") for i in range(len(frequencies))]\n",
    "\n",
    "    MW_Pix = s2wav.synthesis(ILC_trimmed_wav_maps, L = L_max, f_scal = f_scal, filters = filter, N = 1)\n",
    "    title = \"ILC CMB Map realization: \"\n",
    "    visualize_wavelet_coefficient_map(MW_Pix, title, str(realizations[i]))\n",
    "    np.save(f\"ILC/synthesized_ILC_MW_maps/ILC_MW_Map_R{realization}\", MW_Pix)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
