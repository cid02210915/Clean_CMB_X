{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4da4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# import pys2let as ps\n",
    "import os\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import s2fft\n",
    "from s2wav import filters\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import s2wav\n",
    "import skyclean\n",
    "import time\n",
    "import math\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e23baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ILC\n",
      "Directory already exists: ILC/covariance_matrix\n",
      "Directory already exists: ILC/ILC_doubled_maps\n",
      "Directory already exists: ILC/ILC_processed_wavelet_maps\n",
      "Directory already exists: ILC/synthesized_ILC_MW_maps\n",
      "Directory already exists: ILC/wavelet_doubled\n",
      "Directory already exists: ILC/weight_vector_data\n"
     ]
    }
   ],
   "source": [
    "def check_and_create_ilc_directories():\n",
    "    \"\"\"\n",
    "    Checks for the existence of a specific nested directory structure for ILC processing and creates any missing directories.\n",
    "    This includes handling multiple levels of nested directories as shown in the provided folder structure.\n",
    "\n",
    "    The structure checked is:\n",
    "    - ILC\n",
    "      - covariance_matrix\n",
    "      - ILC_doubled_maps\n",
    "      - ILC_processed_wavelet_maps\n",
    "      - synthesized_ILC_MW_maps\n",
    "      - wavelet_doubled\n",
    "      - weight_vector_data\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the root directories\n",
    "    # base_dir = \"path_to_base_directory\"  # Set this to your base directory path\n",
    "    # ilc_dir = os.path.join(base_dir, \"ILC\")\n",
    "    ilc_dir = \"ILC\"\n",
    "    # List of directories under the ILC directory\n",
    "    ilc_sub_dirs = [\"covariance_matrix\", \"ILC_doubled_maps\", \"ILC_processed_wavelet_maps\", \"synthesized_ILC_MW_maps\",\"wavelet_doubled\",\"weight_vector_data\"]\n",
    "\n",
    "    # Create the ILC directory and its subdirectories\n",
    "    create_directory(ilc_dir)\n",
    "    for sub_dir in ilc_sub_dirs:\n",
    "        create_directory(os.path.join(ilc_dir, sub_dir))\n",
    "\n",
    "def create_directory(dir_path):\n",
    "    \"\"\"\n",
    "    Checks if a directory exists, and if not, creates it. Prints the status of the directory.\n",
    "    \n",
    "    Parameters:\n",
    "        dir_path (str): The path of the directory to check and create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(f\"Created directory: {dir_path}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {dir_path}\")\n",
    "\n",
    "# Run the function to check and create directories as needed\n",
    "check_and_create_ilc_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5017cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mw_alm_2_hp_alm(MW_alm, lmax):\n",
    "    \"\"\"\n",
    "    Converts MW alm coefficients to HEALPix alm coefficients.\n",
    "\n",
    "    Args:\n",
    "        MW_alm (ndarray): 2D array of shape (Lmax, 2*Lmax-1) representing MW alm coefficients.\n",
    "        lmax (int): Maximum multipole moment.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: 1D array of HEALPix alm coefficients.\n",
    "    \"\"\"\n",
    "    hp_alm = np.zeros(hp.Alm.getsize(lmax), dtype=np.complex128)\n",
    "    for l in range(lmax + 1):\n",
    "        for m in range(-l, l + 1):\n",
    "            index = hp.Alm.getidx(lmax, l, abs(m))\n",
    "            if m < 0:\n",
    "                hp_alm[index] = (-1)**m * np.conj(MW_alm[l, lmax + m])\n",
    "            else:\n",
    "                hp_alm[index] = MW_alm[l, lmax + m]\n",
    "    return hp_alm\n",
    "\n",
    "def Single_Map_doubleworker(MW_Pix_Map):\n",
    "    \"\"\"\n",
    "    Doubles the resolution of a single wavelet map.\n",
    "\n",
    "    Args:\n",
    "        MW_Pix_Map (ndarray): Wavelet pixel map to be doubled in resolution.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Doubled resolution wavelet map.\n",
    "    \"\"\"\n",
    "    MW_alm = s2fft.forward(MW_Pix_Map, L=MW_Pix_Map.shape[1])\n",
    "    L = MW_alm.shape[0]\n",
    "    padded_alm = np.zeros((2*L-1, 2*(2*L-1)-1), dtype=np.complex128)\n",
    "    \n",
    "    inner_matrix_middle = MW_alm.shape[1] // 2\n",
    "    outer_matrix_middle = padded_alm.shape[1] // 2\n",
    "    start_col = outer_matrix_middle - inner_matrix_middle\n",
    "    end_col = start_col + MW_alm.shape[1]\n",
    "      \n",
    "    padded_alm[:MW_alm.shape[0], start_col:end_col] = MW_alm\n",
    "    MW_Pix_Map_doubled = np.real(s2fft.inverse(padded_alm, L=padded_alm.shape[0]))\n",
    "    \n",
    "    return MW_Pix_Map_doubled\n",
    "\n",
    "def load_frequency_data(file_template, frequencies, scales, realization):\n",
    "    \"\"\"\n",
    "    Loads wavelet data from files for different frequencies and scales.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): Base directory containing the wavelet files.\n",
    "        file_template (str): Template string for file paths with placeholders for frequency, scale, and realization.\n",
    "        frequencies (list): List of frequency strings.\n",
    "        scales (list): List of scale indices.\n",
    "        realization (str): Realization identifier as a string.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary where keys are tuples (frequency, scale) and values are loaded wavelet data arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    frequency_data = {}\n",
    "    realization = str(realization).zfill(4)\n",
    "    for frequency in frequencies:\n",
    "        for scale in scales:\n",
    "            path = f\"{file_template.format(frequency=frequency, scale=scale, realization=realization)}\"\n",
    "            # print(path)\n",
    "            try:\n",
    "                frequency_data[(frequency, scale)] = np.load(path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {path} for frequency {frequency} and scale {scale}: {e}, realization {realization}\")\n",
    "    return frequency_data\n",
    "\n",
    "def save_doubled_wavelet_map(args):\n",
    "    \"\"\"\n",
    "    Helper function to save a doubled wavelet map.\n",
    "\n",
    "    Args:\n",
    "        args (tuple): Contains the wavelet map data, frequency, scale, realization, and path template.\n",
    "    \"\"\"\n",
    "    original_map, frequency, scale, realization, path_template = args\n",
    "    doubled_map = Single_Map_doubleworker(original_map)\n",
    "    save_path = path_template.format(frequency=frequency, scale=scale, realization=realization)\n",
    "    np.save(save_path, doubled_map)\n",
    "\n",
    "def double_and_save_wavelet_maps_MP(original_wavelet_c_j, frequencies, scales, realization, path_template):\n",
    "    \"\"\"\n",
    "    Doubles the resolution of the wavelet coefficient maps using multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        original_wavelet_c_j (dict): Dictionary containing the original wavelet maps.\n",
    "        frequencies (list): List of frequency strings.\n",
    "        scales (list): List of scale indices.\n",
    "        realization (str): The realization number for file naming.\n",
    "        path_template (str): Template for saving the doubled wavelet maps.\n",
    "    \"\"\"\n",
    "    tasks = [(original_wavelet_c_j[(i, j)], i, j, realization, path_template) for i in frequencies for j in scales]\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        executor.map(save_doubled_wavelet_map, tasks)\n",
    "\n",
    "def smoothed_covariance(MW_Map1, MW_Map2):\n",
    "    \"\"\"\n",
    "    Computes covariance between two wavelet maps with smoothing.\n",
    "\n",
    "    Args:\n",
    "        MW_Map1 (ndarray): First wavelet coefficient map.\n",
    "        MW_Map2 (ndarray): Second wavelet coefficient map.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Smoothed covariance map.\n",
    "    \"\"\"\n",
    "    smoothing_lmax = MW_Map1.shape[0]\n",
    "    map1 = np.real(MW_Map1)\n",
    "    map2 = np.real(MW_Map2)\n",
    "    R_MW_Pixel_map = np.multiply(map1, map2) + 0.j\n",
    "\n",
    "    R_MW_alm = s2fft.forward(R_MW_Pixel_map, L=smoothing_lmax)\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = R_MW_alm.shape[0]\n",
    "    npix = hp.nside2npix(1 << (int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    gauss_smooth = hp.gauss_beam(scale_fwhm, lmax=smoothing_lmax-1)\n",
    "    MW_alm_beam_convolved = np.zeros(R_MW_alm.shape, dtype=np.complex128)\n",
    "\n",
    "    for i in range(R_MW_alm.shape[1]):\n",
    "        MW_alm_beam_convolved[:, i] = R_MW_alm[:, i] * gauss_smooth\n",
    "    \n",
    "    R_covariance_map = np.real(s2fft.inverse(MW_alm_beam_convolved, L=smoothing_lmax))\n",
    "    return R_covariance_map\n",
    "\n",
    "\n",
    "def compute_covariance(task):\n",
    "    \"\"\"\n",
    "    Computes the covariance between two frequency maps at a given scale.\n",
    "    \n",
    "    Args:\n",
    "    task (tuple): A tuple containing (i, fq, frequencies, scale, doubled_MW_wav_c_j).\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing indices i, fq and the computed covariance matrix.\n",
    "    \"\"\"\n",
    "    i, fq, frequencies, scale, doubled_MW_wav_c_j = task\n",
    "    key_i = (frequencies[i], scale)\n",
    "    key_fq = (frequencies[fq], scale)\n",
    "    if key_i not in doubled_MW_wav_c_j or key_fq not in doubled_MW_wav_c_j:\n",
    "        raise KeyError(f\"Missing data for keys {key_i} or {key_fq}.\")\n",
    "    return i, fq, smoothed_covariance(doubled_MW_wav_c_j[key_i], doubled_MW_wav_c_j[key_fq])\n",
    "\n",
    "def calculate_covariance_matrix_MP(frequencies, doubled_MW_wav_c_j, scale, realization, path_template):\n",
    "    \"\"\"\n",
    "    Calculates the covariance matrices for all given frequencies and saves them to disk using a provided template,\n",
    "    accommodating any size of the input data arrays using multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        frequencies (list): List of frequency indices.\n",
    "        doubled_MW_wav_c_j (dict): Dictionary containing data arrays for covariance calculations.\n",
    "        scale (int): The scale.\n",
    "        realization (str): The realization identifier.\n",
    "        path_template (str): Template string for saving the covariance matrices, with placeholders for combined frequencies, scale, and realization.\n",
    "        \n",
    "    Returns:\n",
    "        full_array: np.ndarray: A 4D array containing the covariance matrices for the given frequencies.\n",
    "    \"\"\"\n",
    "    if frequencies:\n",
    "        sample_data = doubled_MW_wav_c_j.get((frequencies[0], scale))\n",
    "        if sample_data is None:\n",
    "            raise KeyError(f\"Data for frequency '{frequencies[0]}' and scale '{scale}' is missing.\")\n",
    "        n_rows, n_cols = sample_data.shape\n",
    "    else:\n",
    "        raise ValueError(\"Frequency list is empty.\")\n",
    "    \n",
    "    total_frequency = len(frequencies)\n",
    "    full_array = np.zeros((total_frequency, total_frequency, n_rows, n_cols))\n",
    "    \n",
    "    # Calculate the covariance matrix and save each one\n",
    "    # Calculate the upper triangle only since the matrix is symmetric\n",
    "    tasks = [(i, fq, frequencies, scale, doubled_MW_wav_c_j) for i in range(total_frequency) for fq in range(i, total_frequency)]\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(compute_covariance, tasks)\n",
    "        for result in results:\n",
    "            i, fq, covariance_matrix = result\n",
    "            full_array[i, fq] = covariance_matrix\n",
    "    \n",
    "    # Testing if the multiprocessing output is the same as the single process output \n",
    "    # np.save(f\"ILC/covariance_matrix/half_cov_1_{scale}\", full_array)\n",
    "    \n",
    "    # Fill the symmetric part of the matrix\n",
    "    for l1 in range(1, total_frequency):\n",
    "        for l2 in range(l1):\n",
    "            full_array[l1, l2] = full_array[l2, l1]\n",
    "\n",
    "    f_str = '_'.join(frequencies)\n",
    "    save_path = path_template.format(frequencies=f_str, scale=scale, realization=realization)\n",
    "    np.save(save_path, full_array)\n",
    "\n",
    "    return full_array\n",
    "\n",
    "def compute_weight_vector(R, scale, realization, weight_vector_matrix_template):\n",
    "    \"\"\"\n",
    "    Processes the given 4D matrix R by computing and saving the weight vectors for each matrix in the first two dimensions.\n",
    "    \n",
    "    Args:\n",
    "        R (np.ndarray): The input covariance matrix, either 2D or 4D.\n",
    "        scale (int): The scale index.\n",
    "        realization (str): The realization identifier.\n",
    "        weight_vector_matrix_template (str): Template for saving the weight vector matrices.\n",
    "\n",
    "    Returns:\n",
    "        Returns:\n",
    "        inverses: (np.ndarray): An Array containing the inverse matrices\n",
    "        weight_vectors (np.ndarray): A 3D Array containing the weight vector.\n",
    "        The size of the first two dimensions of the weight vector is the size of the wavelet coefficient map at the given scale.\n",
    "        The third dimension is the weight vector (The contribution from each frequency).\n",
    "        Each element of the weight vector is a 1D array.\n",
    "        singular_matrices_location (list): The locations of singular matrices.\n",
    "    \"\"\"\n",
    "    if R.ndim == 4:\n",
    "        R_Pix = np.swapaxes(np.swapaxes(R, 0, 2), 1, 3)\n",
    "        dim1, dim2 = R_Pix.shape[:2]\n",
    "        subdim1, subdim2 = R_Pix.shape[2:]\n",
    "    elif R.ndim == 2:\n",
    "        R_Pix = R\n",
    "        dim1, dim2 = 1, 1\n",
    "        subdim1, subdim2 = R_Pix.shape\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected array dimension: {R.ndim}\")\n",
    "\n",
    "    identity_vector = np.ones(subdim2, dtype=float)\n",
    "    inverses = np.zeros((dim1, dim2, subdim1, subdim2)) if R.ndim == 4 else np.zeros((subdim1, subdim2))\n",
    "    weight_vectors = np.zeros((dim1, dim2, subdim1)) if R.ndim == 4 else np.zeros(subdim1)\n",
    "    singular_matrices_location = []\n",
    "\n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            try:\n",
    "                if R.ndim == 4:\n",
    "                    inverse_matrix = np.linalg.inv(R_Pix[i, j])\n",
    "                    inverses[i, j] = inverse_matrix\n",
    "                    numerator = np.dot(inverse_matrix, identity_vector)\n",
    "                    denominator = np.dot(numerator, identity_vector)\n",
    "                    weight_vectors[i, j] = numerator / denominator\n",
    "                else:\n",
    "                    inverse_matrix = np.linalg.inv(R_Pix)\n",
    "                    inverses = inverse_matrix\n",
    "                    numerator = np.dot(inverse_matrix, identity_vector)\n",
    "                    denominator = np.dot(numerator, identity_vector)\n",
    "                    weight_vectors = numerator / denominator\n",
    "            except np.linalg.LinAlgError:\n",
    "                singular_matrices_location.append((i, j))\n",
    "                singular_matrix_path = weight_vector_matrix_template.format(\n",
    "                    type=\"inverse_singular_matrix\", scale=scale, realization=realization, i=i, j=j\n",
    "                )\n",
    "                np.save(singular_matrix_path, R_Pix[i, j] if R.ndim == 4 else R_Pix)\n",
    "                if R.ndim == 4:\n",
    "                    weight_vectors[i, j] = np.zeros(len(identity_vector))\n",
    "                else:\n",
    "                    weight_vectors = np.zeros(len(identity_vector))\n",
    "\n",
    "    np.save(weight_vector_matrix_template.format(type=\"weight_vector\", scale=scale, realization=realization), weight_vectors)\n",
    "    return inverses, weight_vectors, singular_matrices_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf6c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_matrix_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function for processing a single matrix in parallel.\n",
    "\n",
    "    Args:\n",
    "        args (tuple): Arguments including the matrix to process, indices, and paths for saving.\n",
    "    \"\"\"\n",
    "    R_Pix_ij, i, j, scale, realization, identity_vector, inverses, weight_vectors, singular_matrices_location, path_template = args\n",
    "    \n",
    "    try:\n",
    "        inverses[i, j] = np.linalg.inv(R_Pix_ij)\n",
    "        numerator = np.dot(inverses[i, j], identity_vector)\n",
    "        denominator = np.dot(numerator, identity_vector)\n",
    "        weight_vectors[i, j] = numerator / denominator\n",
    "    except np.linalg.LinAlgError:\n",
    "        singular_matrices_location.append((i, j))\n",
    "        np.save(path_template.format(type=\"inverse_singular_matrix\", scale=scale, realization=realization, i=i, j=j), R_Pix_ij)\n",
    "        weight_vectors[i, j] = np.zeros(len(identity_vector))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_ILC_for_pixel(i, j, frequencies, scale, weight_vector_load, doubled_MW_wav_c_j):\n",
    "    pix_vector = np.array([\n",
    "        doubled_MW_wav_c_j[(frequencies[k], scale)][i, j] for k in range(len(frequencies))\n",
    "    ])\n",
    "    return np.dot(weight_vector_load[scale][i, j], pix_vector)\n",
    "\n",
    "def create_doubled_ILC_map(frequencies, scale, weight_vector_load, doubled_MW_wav_c_j, realization):\n",
    "    size = doubled_MW_wav_c_j[(frequencies[0],scale)].shape\n",
    "    doubled_map = np.zeros((size[0], size[1]))\n",
    "    \n",
    "    for i in range(doubled_map.shape[0]):\n",
    "        for j in range(doubled_map.shape[1]):\n",
    "            doubled_map[i, j] = compute_ILC_for_pixel(i, j, frequencies, scale,weight_vector_load, doubled_MW_wav_c_j)\n",
    "    np.save(f\"ILC/ILC_doubled_maps/ILC_Map_S{scale}_R{realization}_MP\", doubled_map)\n",
    "    return doubled_map\n",
    "\n",
    "def trim_to_original(MW_Doubled_Map, scale, realization, path_template):\n",
    "    \"\"\"\n",
    "    Trims the doubled map to its original resolution.\n",
    "\n",
    "    Args:\n",
    "        MW_Doubled_Map (ndarray): Doubled wavelet map to be trimmed.\n",
    "        scale (int): Scale index.\n",
    "        realization (str): The realization number for file naming.\n",
    "        path_template (str): Template for saving the trimmed maps.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Trimmed wavelet map.\n",
    "    \"\"\"\n",
    "    MW_alm_doubled = s2fft.forward(MW_Doubled_Map, L=MW_Doubled_Map.shape[0])\n",
    "    inner_matrix_vertical = (MW_Doubled_Map.shape[0] + 1) // 2\n",
    "    inner_matrix_horizontal = 2 * inner_matrix_vertical - 1\n",
    "    \n",
    "    inner_matrix_middle = inner_matrix_horizontal // 2\n",
    "    outer_matrix_middle = MW_Doubled_Map.shape[1] // 2\n",
    "    start_col = outer_matrix_middle - inner_matrix_middle\n",
    "    end_col = start_col + inner_matrix_horizontal\n",
    "\n",
    "    trimmed_alm = MW_alm_doubled[:inner_matrix_vertical, start_col:end_col]\n",
    "    MW_Pix_Map_original = s2fft.inverse(trimmed_alm, L=trimmed_alm.shape[0])[np.newaxis, ...]\n",
    "    np.save(path_template.format(scale=scale, realization=realization), MW_Pix_Map_original)\n",
    "    return MW_Pix_Map_original\n",
    "\n",
    "def visualize_MW_Pix_map(MW_Pix_Map, title, coord=[\"G\"], unit = r\"K\", is_MW_alm = False):\n",
    "    \"\"\"\n",
    "    Processes a MW pixel wavelet coefficient map and visualizes it using HEALPix mollview.\n",
    "\n",
    "    Parameters:\n",
    "        MW_Pix_Map (numpy array): Array representing the wavelet coefficient map.\n",
    "        title (str): Title for the visualization plot.\n",
    "\n",
    "    Returns:\n",
    "        Only Displays a mollview map.\n",
    "    \"\"\"\n",
    "    if not is_MW_alm:\n",
    "        # The newly generated wavelet coefficient map is in three dimensions\n",
    "        if len(MW_Pix_Map.shape) == 3:\n",
    "            L_max = MW_Pix_Map.shape[1]\n",
    "        else:\n",
    "            L_max = MW_Pix_Map.shape[0]\n",
    "        original_map_alm = s2fft.forward(MW_Pix_Map, L=L_max)\n",
    "        print(\"MW alm shape:\", original_map_alm.shape)\n",
    "    else:\n",
    "        original_map_alm = MW_Pix_Map\n",
    "        L_max = original_map_alm.shape[0]\n",
    "    original_map_hp_alm = mw_alm_2_hp_alm(original_map_alm, L_max - 1)\n",
    "    original_hp_map = hp.alm2map(original_map_hp_alm, nside=(L_max - 1)//2)\n",
    "\n",
    "    hp.mollview(\n",
    "        original_hp_map,\n",
    "        coord=coord,\n",
    "        title=title,\n",
    "        unit=unit,\n",
    "        # min=min, max=max,  # Uncomment and adjust these as necessary for better visualization contrast\n",
    "    )\n",
    "    # plt.figure(dpi=1200)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def synthesize_ILC_maps(trimmed_maps, realization, output_templates, L_max, N_directions):\n",
    "    \"\"\"\n",
    "    Synthesizes ILC maps from trimmed wavelet maps, visualizes the results, and saves the synthesized maps.\n",
    "\n",
    "    Args:\n",
    "        trimmed_maps (list of np.ndarray): List of trimmed wavelet maps for different scales.\n",
    "        realization (str): The realization identifier.\n",
    "        output_templates (dict): Dictionary of output path templates for different processing steps.\n",
    "        L_max (int): Maximum spherical harmonic degree.\n",
    "        N_directions (int): Number of directions for the directional wavelet filters.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The synthesized ILC map.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the scaling coefficients using the template path\n",
    "    f_scal = np.load(output_templates['f_scal'].format(realization=realization))\n",
    "\n",
    "    # Create the directional filters\n",
    "    filter = filters.filters_directional_vectorised(L_max, N_directions)\n",
    "\n",
    "    # Perform the synthesis to obtain the ILC map\n",
    "    MW_Pix = s2wav.synthesis(trimmed_maps, L=L_max, f_scal=f_scal, filters=filter, N=N_directions)\n",
    "\n",
    "    # Visualize the synthesized ILC map\n",
    "    title = f\"ILC CMB Map realization: {realization}\"\n",
    "    visualize_MW_Pix_map(MW_Pix, title)\n",
    "\n",
    "    # Save the synthesized ILC map\n",
    "    np.save(output_templates['synthesized_maps'].format(realization=realization), MW_Pix)\n",
    "    \n",
    "    return MW_Pix\n",
    "\n",
    "\n",
    "\n",
    "def ILC_wav_coeff_maps_MP(file_template, frequencies, scales, realizations, output_templates, L_max, N_directions):\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes wavelet maps for a range of realizations, including doubling, covariance calculation,\n",
    "    matrix processing, and trimming to original resolution, using multiprocessing for efficiency\n",
    "    where tasks are independent.\n",
    "\n",
    "    Args:\n",
    "        file_template (str): Template string for file paths with placeholders for frequency, scale, and realization.\n",
    "        frequencies (list): List of frequency strings.\n",
    "        scales (list): List of scale indices.\n",
    "        realizations (list): List of realizations to process.\n",
    "        output_templates (dict): Dictionary of output path templates for different processing steps.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of trimmed maps for the final processed realization.\n",
    "    \"\"\"\n",
    "\n",
    "    synthesized_maps = []\n",
    "\n",
    "    for realization in realizations:\n",
    "        realization_str = str(realization).zfill(4)\n",
    "        print(f\"Processing realization {realization_str}\")\n",
    "        path = output_templates['trimmed_maps'].format(scale=scales[0], realization=realization_str)\n",
    "        \n",
    "        # Timing for loading the original wavelet maps\n",
    "        # start_time = time.perf_counter()\n",
    "        original_wavelet_c_j = load_frequency_data(file_template, frequencies, scales, realization_str)\n",
    "        # load_time = time.perf_counter() - start_time\n",
    "        # print(f'Loaded original wavelet maps in {load_time:.2f} seconds')\n",
    "\n",
    "        # Timing for doubling and saving wavelet maps\n",
    "        start_time = time.perf_counter()\n",
    "        double_and_save_wavelet_maps_MP(original_wavelet_c_j, frequencies, scales, realization_str, output_templates['doubled_maps'])\n",
    "        double_time = time.perf_counter() - start_time\n",
    "        print(f'Doubled and saved wavelet maps in {double_time:.2f} seconds')\n",
    "\n",
    "        # loading doubled wavelet maps\n",
    "        doubled_MW_wav_c_j = load_frequency_data(output_templates['doubled_maps'], frequencies, scales, realization_str)\n",
    "       \n",
    "\n",
    "        # Timing for calculating covariance matrices with multiprocessing\n",
    "        start_time = time.perf_counter()\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            covariance_tasks = [\n",
    "                executor.submit(\n",
    "                    calculate_covariance_matrix_MP,\n",
    "                    frequencies, doubled_MW_wav_c_j, scale, realization_str, output_templates['covariance_matrices']\n",
    "                )\n",
    "                for scale in scales\n",
    "            ]\n",
    "            for future in concurrent.futures.as_completed(covariance_tasks):\n",
    "                future.result()  # Wait for all tasks to complete\n",
    "        covariance_time = time.perf_counter() - start_time\n",
    "        print(f'Calculated covariance matrices in {covariance_time:.2f} seconds')\n",
    "\n",
    "        # Timing for processing and saving matrices with multiprocessing\n",
    "        start_time = time.perf_counter()\n",
    "        F_str = '_'.join(frequencies)\n",
    "        R_covariance = [\n",
    "            np.load(output_templates['covariance_matrices'].format(\n",
    "                frequencies=F_str, scale=i, realization=realization_str))\n",
    "            for i in range(len(scales))\n",
    "        ]\n",
    "        \n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            process_tasks = [\n",
    "                executor.submit(\n",
    "                    compute_weight_vector,\n",
    "                    R_covariance[scale_idx], scale, realization_str, output_templates['weight_vector_matrices']\n",
    "                )\n",
    "                for scale_idx, scale in enumerate(scales)\n",
    "            ]\n",
    "            for future in concurrent.futures.as_completed(process_tasks):\n",
    "                future.result()  # Wait for all tasks to complete\n",
    "        process_time = time.perf_counter() - start_time\n",
    "        print(f'Calculate weight vector matrices in {process_time:.2f} seconds')\n",
    "\n",
    "        # Timing for creating ILC maps with multiprocessing\n",
    "        start_time = time.perf_counter()\n",
    "        weight_vector_load = [\n",
    "            np.load(output_templates['weight_vector_matrices'].format(\n",
    "                type=\"weight_vector\", scale=i, realization=realization_str))\n",
    "            for i in range(len(scales))\n",
    "        ]\n",
    "\n",
    "        ####################\n",
    "        # Unused code for creating doubled ILC map: multiprocessing is slow \n",
    "        # with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        #     # Submit tasks for each scale to be processed in parallel\n",
    "        #     futures = [\n",
    "        #         executor.submit(\n",
    "        #             create_doubled_ILC_map,\n",
    "        #             frequencies, scale, weight_vector_load, doubled_MW_wav_c_j, realization_str, output_templates['ilc_maps']\n",
    "        #         )\n",
    "        #         for scale in scales\n",
    "        #     ]\n",
    "            \n",
    "        #     # Collect the results as they complete\n",
    "        #     doubled_maps = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    \n",
    "        #####################\n",
    "        \n",
    "        doubled_maps = []\n",
    "        for i in range(len(scales)):\n",
    "            doubled_maps.append(create_doubled_ILC_map(frequencies, scales[i], weight_vector_load, doubled_MW_wav_c_j, realization=realization_str))\n",
    "\n",
    "        doubled_maps = [np.load(f\"ILC/ILC_doubled_maps/ILC_Map_S{i}_R{realization_str}_MP.npy\") for i in range(len(scales))]\n",
    "\n",
    "        ilc_time = time.perf_counter() - start_time\n",
    "        print(f'Created ILC maps in {ilc_time:.2f} seconds')\n",
    "\n",
    "        # Load the ILC maps\n",
    "        doubled_maps = [np.load(output_templates['ilc_maps'].format(scale=i, realization=realization_str)) for i in range(len(scales))]\n",
    "\n",
    "        # Timing for trimming to original resolution with multiprocessing\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(trim_to_original, doubled_maps[scale], scale, realization_str, output_templates['trimmed_maps'])\n",
    "                for scale in scales\n",
    "            ]\n",
    "            trimmed_maps = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "        trim_time = time.perf_counter() - start_time\n",
    "        print(f'Trimmed maps to original resolution in {trim_time:.2f} seconds')\n",
    "\n",
    "        # Timing for visualizing wavelet coefficient maps\n",
    "        start_time = time.perf_counter()\n",
    "        for scale in scales:\n",
    "            title = \"ILC Wavelet coefficient map at scale: \"\n",
    "            visualize_MW_Pix_map(trimmed_maps[scale], title + str(scale))\n",
    "        visualize_time = time.perf_counter() - start_time\n",
    "        print(f'Visualized wavelet coefficient maps in {visualize_time:.2f} seconds')\n",
    "        \n",
    "\n",
    "        # Synthesize the ILC map from the trimmed maps\n",
    "        synthesized_map = synthesize_ILC_maps(trimmed_maps, realization_str, output_templates, L_max, N_directions)\n",
    "        synthesized_maps.append(synthesized_map)\n",
    "        \n",
    "\n",
    "    return synthesized_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c954f357",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'realizations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m N_directions = \u001b[32m1\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     realization = \u001b[38;5;28mstr\u001b[39m(realizations[r]).zfill(\u001b[32m4\u001b[39m)\n\u001b[32m      5\u001b[39m     trimmed_maps = [np.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/home/cindy/Clean_CMB-main/Clean_CMB/ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_R\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrealization\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_MP.npy\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m scale \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scales))]\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scales)):\n",
      "\u001b[31mNameError\u001b[39m: name 'realizations' is not defined"
     ]
    }
   ],
   "source": [
    "L_max = 32\n",
    "N_directions = 1\n",
    "for r in range(1):\n",
    "    realization = str(realizations[r]).zfill(4)\n",
    "    trimmed_maps = [np.load(f\"/home/cindy/Clean_CMB-main/Clean_CMB/ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S{scale}_R{realization}_MP.npy\") for scale in range(len(scales))]\n",
    "    for j in range(len(scales)):\n",
    "        visualize_MW_Pix_map(trimmed_maps[j], \"ILC wavelet coefficient map at scale: \" + str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92672eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s2wav import filters\n",
    "import numpy as np\n",
    "import s2wav\n",
    "import s2fft\n",
    "L_max = 32\n",
    "N_directions = 1\n",
    "scales = [0, 1, 2, 3, 4, 5]\n",
    "realizations = [0]\n",
    "for i in range(len(realizations)):\n",
    "    realization = str(realizations[i]).zfill(4)\n",
    "    trimmed_maps = [np.load(f\"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S{scale}_R{realization}_MP.npy\") for scale in range(len(scales))]\n",
    "\n",
    "    filter = filters.filters_directional_vectorised(L_max, N_directions)\n",
    "    # f_scal = np.array([[0]]) #np.load(f\"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_F030.npy\") \n",
    "    f_scal = np.load(f\"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_F100_R{realization}.npy\") \n",
    "\n",
    "    # [np.load(f\"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_F{frequencies[i]}.npy\") for i in range(len(frequencies))]\n",
    "\n",
    "    MW_Pix = s2wav.synthesis(trimmed_maps, L = L_max, f_scal = f_scal, filters = filter, N = 1)\n",
    "    title = \"ILC CMB Map realization: \"\n",
    "    visualize_MW_Pix_map(MW_Pix, title + str(realizations[i]))\n",
    "    np.save(f\"ILC/synthesized_ILC_MW_maps/ILC_MW_Map_R{realization}\", MW_Pix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_cmb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
