{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fadedb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "# import pys2let as ps \n",
    "import os\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import s2fft\n",
    "from s2wav import filters\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import s2wav\n",
    "import skyclean\n",
    "import time\n",
    "import math\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c19b751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ILC\n",
      "Directory already exists: ILC/covariance_matrix\n",
      "Directory already exists: ILC/ILC_doubled_maps\n",
      "Directory already exists: ILC/ILC_processed_wavelet_maps\n",
      "Directory already exists: ILC/synthesized_ILC_MW_maps\n",
      "Directory already exists: ILC/wavelet_doubled\n",
      "Directory already exists: ILC/weight_vector_data\n"
     ]
    }
   ],
   "source": [
    "def check_and_create_ilc_directories():\n",
    "    \"\"\"\n",
    "    Checks for the existence of a specific nested directory structure for ILC processing and creates any missing directories.\n",
    "    This includes handling multiple levels of nested directories as shown in the provided folder structure.\n",
    "\n",
    "    The structure checked is:\n",
    "    - ILC\n",
    "      - covariance_matrix\n",
    "      - ILC_doubled_maps\n",
    "      - ILC_processed_wavelet_maps\n",
    "      - synthesized_ILC_MW_maps\n",
    "      - wavelet_doubled\n",
    "      - weight_vector_data\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the root directories\n",
    "    # base_dir = \"path_to_base_directory\"  # Set this to your base directory path\n",
    "    # ilc_dir = os.path.join(base_dir, \"ILC\")\n",
    "    ilc_dir = \"ILC\"\n",
    "    # List of directories under the ILC directory\n",
    "    ilc_sub_dirs = [\"covariance_matrix\", \"ILC_doubled_maps\", \"ILC_processed_wavelet_maps\", \"synthesized_ILC_MW_maps\",\"wavelet_doubled\",\"weight_vector_data\"]\n",
    "\n",
    "    # Create the ILC directory and its subdirectories\n",
    "    create_directory(ilc_dir)\n",
    "    for sub_dir in ilc_sub_dirs:\n",
    "        create_directory(os.path.join(ilc_dir, sub_dir))\n",
    "\n",
    "def create_directory(dir_path):\n",
    "    \"\"\"\n",
    "    Checks if a directory exists, and if not, creates it. Prints the status of the directory.\n",
    "    \n",
    "    Parameters:\n",
    "        dir_path (str): The path of the directory to check and create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(f\"Created directory: {dir_path}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {dir_path}\")\n",
    "\n",
    "# Run the function to check and create directories as needed\n",
    "check_and_create_ilc_directories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18baf276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mw_alm_2_hp_alm(MW_alm, lmax):\n",
    "    \"\"\"\n",
    "    Converts MW alm coefficients to HEALPix alm coefficients.\n",
    "\n",
    "    Args:\n",
    "        MW_alm (ndarray): 2D array of shape (Lmax, 2*Lmax-1) representing MW alm coefficients.\n",
    "        lmax (int): Maximum multipole moment.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: 1D array of HEALPix alm coefficients.\n",
    "    \"\"\"\n",
    "    hp_alm = np.zeros(hp.Alm.getsize(lmax), dtype=np.complex128)\n",
    "    for l in range(lmax + 1):\n",
    "        for m in range(-l, l + 1):\n",
    "            index = hp.Alm.getidx(lmax, l, abs(m))\n",
    "            if m < 0:\n",
    "                hp_alm[index] = (-1)**m * np.conj(MW_alm[l, lmax + m])\n",
    "            else:\n",
    "                hp_alm[index] = MW_alm[l, lmax + m]\n",
    "    return hp_alm\n",
    "\n",
    "def Single_Map_doubleworker(MW_Pix_Map):\n",
    "    \"\"\"\n",
    "    Doubles the resolution of a single wavelet map.\n",
    "\n",
    "    Args:\n",
    "        MW_Pix_Map (ndarray): Wavelet pixel map to be doubled in resolution.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Doubled resolution wavelet map.\n",
    "    \"\"\"\n",
    "    MW_alm = s2fft.forward(MW_Pix_Map, L=MW_Pix_Map.shape[1])\n",
    "    L = MW_alm.shape[0]\n",
    "    padded_alm = np.zeros((2*L-1, 2*(2*L-1)-1), dtype=np.complex128)\n",
    "    \n",
    "    inner_matrix_middle = MW_alm.shape[1] // 2\n",
    "    outer_matrix_middle = padded_alm.shape[1] // 2\n",
    "    start_col = outer_matrix_middle - inner_matrix_middle\n",
    "    end_col = start_col + MW_alm.shape[1]\n",
    "      \n",
    "    padded_alm[:MW_alm.shape[0], start_col:end_col] = MW_alm\n",
    "    MW_Pix_Map_doubled = np.real(s2fft.inverse(padded_alm, L=padded_alm.shape[0]))\n",
    "    \n",
    "    return MW_Pix_Map_doubled\n",
    "\n",
    "def load_frequency_data(file_template, frequencies, scales, realization, component):\n",
    "    \"\"\"\n",
    "    Loads wavelet data from files for different frequencies and scales.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): Base directory containing the wavelet files.\n",
    "        file_template (str): Template string for file paths with placeholders for frequency, scale, and realization.\n",
    "        frequencies (list): List of frequency strings.\n",
    "        scales (list): List of scale indices.\n",
    "        realization (str): Realization identifier as a string.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary where keys are tuples (frequency, scale) and values are loaded wavelet data arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    frequency_data = {}\n",
    "    realization = str(realization).zfill(4)\n",
    "    for frequency in frequencies:\n",
    "        for scale in scales:\n",
    "            path = f\"{file_template.format(frequency=frequency, scale=scale, realization=realization, component=component)}\"\n",
    "            # print(path)\n",
    "            try:\n",
    "                frequency_data[(frequency, scale)] = np.load(path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {path} for frequency {frequency} and scale {scale}: {e}, realization {realization}\")\n",
    "    return frequency_data\n",
    "\n",
    "def save_doubled_wavelet_map(args):\n",
    "    \"\"\"\n",
    "    Helper function to save a doubled wavelet map.\n",
    "\n",
    "    Args:\n",
    "        args (tuple): (wavelet_map, frequency, scale, realization, component, path_template)\n",
    "    \"\"\"\n",
    "    original_map, frequency, scale, realization, component, path_template = args\n",
    "    doubled_map = Single_Map_doubleworker(original_map)\n",
    "    save_path = path_template.format(\n",
    "        component=component,\n",
    "        frequency=frequency,\n",
    "        scale=scale,\n",
    "        realization=realization\n",
    "    )\n",
    "    np.save(save_path, doubled_map)\n",
    "\n",
    "\n",
    "def double_and_save_wavelet_maps_MP(original_wavelet_c_j, frequencies, scales, realization, component, path_template):\n",
    "    \"\"\"\n",
    "    Doubles the resolution of the wavelet coefficient maps using multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        original_wavelet_c_j (dict): Dictionary containing the original wavelet maps.\n",
    "        frequencies (list): List of frequency strings.\n",
    "        scales (list): List of scale indices.\n",
    "        realization (str): The realization number for file naming.\n",
    "        path_template (str): Template for saving the doubled wavelet maps.\n",
    "    \"\"\"\n",
    "    tasks = [(original_wavelet_c_j[(i, j)], i, j, realization, component, path_template) for i in frequencies for j in scales]\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        executor.map(save_doubled_wavelet_map, tasks)\n",
    "\n",
    "def smoothed_covariance(MW_Map1, MW_Map2):\n",
    "    \"\"\"\n",
    "    Computes covariance between two wavelet maps with smoothing.\n",
    "\n",
    "    Args:\n",
    "        MW_Map1 (ndarray): First wavelet coefficient map.\n",
    "        MW_Map2 (ndarray): Second wavelet coefficient map.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Smoothed covariance map.\n",
    "    \"\"\"\n",
    "    smoothing_lmax = MW_Map1.shape[0]\n",
    "    map1 = np.real(MW_Map1)\n",
    "    map2 = np.real(MW_Map2)\n",
    "    R_MW_Pixel_map = np.multiply(map1, map2) + 0.j\n",
    "\n",
    "    R_MW_alm = s2fft.forward(R_MW_Pixel_map, L=smoothing_lmax)\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = R_MW_alm.shape[0]\n",
    "    npix = hp.nside2npix(1 << (int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    gauss_smooth = hp.gauss_beam(scale_fwhm, lmax=smoothing_lmax-1)\n",
    "    MW_alm_beam_convolved = np.zeros(R_MW_alm.shape, dtype=np.complex128)\n",
    "\n",
    "    for i in range(R_MW_alm.shape[1]):\n",
    "        MW_alm_beam_convolved[:, i] = R_MW_alm[:, i] * gauss_smooth\n",
    "    \n",
    "    R_covariance_map = np.real(s2fft.inverse(MW_alm_beam_convolved, L=smoothing_lmax))\n",
    "    return R_covariance_map\n",
    "\n",
    "\n",
    "def compute_covariance(task):\n",
    "    \"\"\"\n",
    "    Computes the covariance between two frequency maps at a given scale.\n",
    "    \n",
    "    Args:\n",
    "    task (tuple): A tuple containing (i, fq, frequencies, scale, doubled_MW_wav_c_j).\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing indices i, fq and the computed covariance matrix.\n",
    "    \"\"\"\n",
    "    i, fq, frequencies, scale, doubled_MW_wav_c_j = task\n",
    "    key_i = (frequencies[i], scale)\n",
    "    key_fq = (frequencies[fq], scale)\n",
    "    if key_i not in doubled_MW_wav_c_j or key_fq not in doubled_MW_wav_c_j:\n",
    "        raise KeyError(f\"Missing data for keys {key_i} or {key_fq}.\")\n",
    "    return i, fq, smoothed_covariance(doubled_MW_wav_c_j[key_i], doubled_MW_wav_c_j[key_fq])\n",
    "\n",
    "def calculate_covariance_matrix_MP(frequencies, doubled_MW_wav_c_j, scale, realization, component, path_template):\n",
    "    \"\"\"\n",
    "    Calculates the covariance matrices for all given frequencies and saves them to disk using a provided template.\n",
    "    \"\"\"\n",
    "\n",
    "    if frequencies:\n",
    "        sample_data = doubled_MW_wav_c_j.get((frequencies[0], scale))\n",
    "        if sample_data is None:\n",
    "            raise KeyError(f\"Data for frequency '{frequencies[0]}' and scale '{scale}' is missing.\")\n",
    "        n_rows, n_cols = sample_data.shape\n",
    "    else:\n",
    "        raise ValueError(\"Frequency list is empty.\")\n",
    "    \n",
    "    total_frequency = len(frequencies)\n",
    "    full_array = np.zeros((total_frequency, total_frequency, n_rows, n_cols))\n",
    "    \n",
    "    # Calculate the covariance (keep your existing logic)\n",
    "    tasks = [(i, fq, frequencies, scale, doubled_MW_wav_c_j) \n",
    "             for i in range(total_frequency) for fq in range(i, total_frequency)]\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(compute_covariance, tasks)\n",
    "        for result in results:\n",
    "            i, fq, covariance_matrix = result\n",
    "            full_array[i, fq] = covariance_matrix\n",
    "    \n",
    "    # Fill the symmetric part of the matrix\n",
    "    for l1 in range(1, total_frequency):\n",
    "        for l2 in range(l1):\n",
    "            full_array[l1, l2] = full_array[l2, l1]\n",
    "\n",
    "    # ✅ Fixed: include component in format to prevent KeyError\n",
    "    f_str = '_'.join(frequencies)\n",
    "    save_path = path_template.format(\n",
    "        component=component,\n",
    "        frequencies=f_str, \n",
    "        scale=scale, \n",
    "        realization=str(realization).zfill(4)   \n",
    "    )\n",
    "    np.save(save_path, full_array)\n",
    "\n",
    "    return full_array\n",
    "\n",
    "\n",
    "def compute_weight_vector(R, scale, realization, weight_vector_matrix_template):\n",
    "    \"\"\"\n",
    "    Processes the given 4D matrix R by computing and saving the weight vectors for each matrix in the first two dimensions.\n",
    "    \n",
    "    Args:\n",
    "        R (np.ndarray): The input covariance matrix, either 2D or 4D.\n",
    "        scale (int): The scale index.\n",
    "        realization (str): The realization identifier.\n",
    "        weight_vector_matrix_template (str): Template for saving the weight vector matrices.\n",
    "\n",
    "    Returns:\n",
    "        Returns:\n",
    "        inverses: (np.ndarray): An Array containing the inverse matrices\n",
    "        weight_vectors (np.ndarray): A 3D Array containing the weight vector.\n",
    "        The size of the first two dimensions of the weight vector is the size of the wavelet coefficient map at the given scale.\n",
    "        The third dimension is the weight vector (The contribution from each frequency).\n",
    "        Each element of the weight vector is a 1D array.\n",
    "        singular_matrices_location (list): The locations of singular matrices.\n",
    "    \"\"\"\n",
    "    if R.ndim == 4:\n",
    "        R_Pix = np.swapaxes(np.swapaxes(R, 0, 2), 1, 3)\n",
    "        dim1, dim2 = R_Pix.shape[:2]\n",
    "        subdim1, subdim2 = R_Pix.shape[2:]\n",
    "    elif R.ndim == 2:\n",
    "        R_Pix = R\n",
    "        dim1, dim2 = 1, 1\n",
    "        subdim1, subdim2 = R_Pix.shape\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected array dimension: {R.ndim}\")\n",
    "\n",
    "    identity_vector = np.ones(subdim2, dtype=float)\n",
    "    inverses = np.zeros((dim1, dim2, subdim1, subdim2)) if R.ndim == 4 else np.zeros((subdim1, subdim2))\n",
    "    weight_vectors = np.zeros((dim1, dim2, subdim1)) if R.ndim == 4 else np.zeros(subdim1)\n",
    "    singular_matrices_location = []\n",
    "\n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            try:\n",
    "                if R.ndim == 4:\n",
    "                    inverse_matrix = np.linalg.inv(R_Pix[i, j])\n",
    "                    inverses[i, j] = inverse_matrix\n",
    "                    numerator = np.dot(inverse_matrix, identity_vector)\n",
    "                    denominator = np.dot(numerator, identity_vector)\n",
    "                    weight_vectors[i, j] = numerator / denominator\n",
    "                else:\n",
    "                    inverse_matrix = np.linalg.inv(R_Pix)\n",
    "                    inverses = inverse_matrix\n",
    "                    numerator = np.dot(inverse_matrix, identity_vector)\n",
    "                    denominator = np.dot(numerator, identity_vector)\n",
    "                    weight_vectors = numerator / denominator\n",
    "            except np.linalg.LinAlgError:\n",
    "                singular_matrices_location.append((i, j))\n",
    "                singular_matrix_path = weight_vector_matrix_template.format(\n",
    "                    type=\"inverse_singular_matrix\", scale=scale, realization=realization, i=i, j=j\n",
    "                )\n",
    "                np.save(singular_matrix_path, R_Pix[i, j] if R.ndim == 4 else R_Pix)\n",
    "                if R.ndim == 4:\n",
    "                    weight_vectors[i, j] = np.zeros(len(identity_vector))\n",
    "                else:\n",
    "                    weight_vectors = np.zeros(len(identity_vector))\n",
    "\n",
    "    np.save(weight_vector_matrix_template.format(type=\"weight_vector\", scale=scale, realization=realization), weight_vectors)\n",
    "    return inverses, weight_vectors, singular_matrices_location\n",
    "\n",
    "def process_matrix_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function for processing a single matrix in parallel.\n",
    "\n",
    "    Args:\n",
    "        args (tuple): Arguments including the matrix to process, indices, and paths for saving.\n",
    "    \"\"\"\n",
    "    R_Pix_ij, i, j, scale, realization, identity_vector, inverses, weight_vectors, singular_matrices_location, component, component_name, path_template = args\n",
    "    \n",
    "    try:\n",
    "        inverses[i, j] = np.linalg.inv(R_Pix_ij)\n",
    "        numerator = np.dot(inverses[i, j], identity_vector)\n",
    "        denominator = np.dot(numerator, identity_vector)\n",
    "        weight_vectors[i, j] = numerator / denominator\n",
    "    except np.linalg.LinAlgError:\n",
    "        singular_matrices_location.append((i, j))\n",
    "        np.save(path_template.format(type=\"inverse_singular_matrix\", component=component, component_name=component_name, scale=scale, realization=realization, i=i, j=j), R_Pix_ij)\n",
    "        weight_vectors[i, j] = np.zeros(len(identity_vector))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_ILC_for_pixel(i, j, frequencies, scale, weight_vector_load, doubled_MW_wav_c_j):\n",
    "    pix_vector = np.array([\n",
    "        doubled_MW_wav_c_j[(frequencies[k], scale)][i, j] for k in range(len(frequencies))\n",
    "    ])\n",
    "    return np.dot(weight_vector_load[scale][i, j], pix_vector)\n",
    "\n",
    "def create_doubled_ILC_map(\n",
    "    frequencies, scale, weight_vector_load, doubled_MW_wav_c_j,\n",
    "    realization, component=None, constraint=False, component_name=None\n",
    "):\n",
    "    size = doubled_MW_wav_c_j[(frequencies[0], scale)].shape\n",
    "    doubled_map = np.zeros(size)\n",
    "\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            doubled_map[i, j] = compute_ILC_for_pixel(\n",
    "                i, j, frequencies, scale, weight_vector_load, doubled_MW_wav_c_j\n",
    "            )\n",
    "\n",
    "    # ✅ Save with proper file naming\n",
    "    if constraint and component_name is not None:\n",
    "        path = f\"ILC/ILC_doubled_maps/ILC_Map_{component}_cilc_{component_name}_S{scale}_R{realization}_MP.npy\"\n",
    "    else:\n",
    "        path = f\"ILC/ILC_doubled_maps/ILC_Map_{component}_S{scale}_R{realization}_MP.npy\"\n",
    "\n",
    "    np.save(path, doubled_map)\n",
    "    return doubled_map\n",
    "\n",
    "\n",
    "def trim_to_original(MW_Doubled_Map, scale, realization, component, component_name, path_template):\n",
    "    \"\"\"\n",
    "    Trims the doubled MW map to its original resolution and saves it.\n",
    "\n",
    "    Args:\n",
    "        MW_Doubled_Map (ndarray): Doubled wavelet map to be trimmed.\n",
    "        scale (int): Scale index.\n",
    "        realization (str or int): The realization number for file naming.\n",
    "        path_template (str): Template for saving the trimmed maps.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Trimmed wavelet map.\n",
    "    \"\"\"\n",
    "    # Forward spherical transform\n",
    "    MW_alm_doubled = s2fft.forward(MW_Doubled_Map, L=MW_Doubled_Map.shape[0])\n",
    "\n",
    "    # Compute inner matrix shape\n",
    "    inner_matrix_vertical = (MW_Doubled_Map.shape[0] + 1) // 2\n",
    "    inner_matrix_horizontal = 2 * inner_matrix_vertical - 1\n",
    "\n",
    "    inner_matrix_middle = inner_matrix_horizontal // 2\n",
    "    outer_matrix_middle = MW_Doubled_Map.shape[1] // 2\n",
    "    start_col = outer_matrix_middle - inner_matrix_middle\n",
    "    end_col = start_col + inner_matrix_horizontal\n",
    "\n",
    "    # Trim spherical harmonics to original resolution\n",
    "    trimmed_alm = MW_alm_doubled[:inner_matrix_vertical, start_col:end_col]\n",
    "\n",
    "    # Inverse transform to pixel domain\n",
    "    MW_Pix_Map_original = s2fft.inverse(trimmed_alm, L=trimmed_alm.shape[0])[np.newaxis, ...]\n",
    "\n",
    "    # Save trimmed map\n",
    "    np.save(\n",
    "        path_template.format(\n",
    "            component=component,\n",
    "            component_name=component_name,\n",
    "            scale=scale,\n",
    "            realization=str(realization).zfill(4)\n",
    "        ),\n",
    "        MW_Pix_Map_original\n",
    "    )\n",
    "\n",
    "    return MW_Pix_Map_original\n",
    "\n",
    "\n",
    "def visualize_MW_Pix_map(MW_Pix_Map, title, coord=[\"G\"], unit = r\"K\", is_MW_alm = False):\n",
    "    \"\"\"\n",
    "    Processes a MW pixel wavelet coefficient map and visualizes it using HEALPix mollview.\n",
    "\n",
    "    Parameters:\n",
    "        MW_Pix_Map (numpy array): Array representing the wavelet coefficient map.\n",
    "        title (str): Title for the visualization plot.\n",
    "\n",
    "    Returns:\n",
    "        Only Displays a mollview map.\n",
    "    \"\"\"\n",
    "    if not is_MW_alm:\n",
    "        # The newly generated wavelet coefficient map is in three dimensions\n",
    "        if len(MW_Pix_Map.shape) == 3:\n",
    "            L_max = MW_Pix_Map.shape[1]\n",
    "        else:\n",
    "            L_max = MW_Pix_Map.shape[0]\n",
    "        original_map_alm = s2fft.forward(MW_Pix_Map, L=L_max)\n",
    "        print(\"MW alm shape:\", original_map_alm.shape)\n",
    "    else:\n",
    "        original_map_alm = MW_Pix_Map\n",
    "        L_max = original_map_alm.shape[0]\n",
    "    original_map_hp_alm = mw_alm_2_hp_alm(original_map_alm, L_max - 1)\n",
    "    original_hp_map = hp.alm2map(original_map_hp_alm, nside=(L_max - 1)//2)\n",
    "\n",
    "    hp.mollview(\n",
    "        original_hp_map,\n",
    "        coord=coord,\n",
    "        title=title,\n",
    "        unit=unit,\n",
    "        # min=min, max=max,  # Uncomment and adjust these as necessary for better visualization contrast\n",
    "    )\n",
    "    # plt.figure(dpi=1200)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def synthesize_ILC_maps(trimmed_maps, realization, output_templates, L_max, N_directions):\n",
    "    \"\"\"\n",
    "    Synthesizes ILC maps from trimmed wavelet maps, visualizes the results, and saves the synthesized maps.\n",
    "\n",
    "    Args:\n",
    "        trimmed_maps (list of np.ndarray): List of trimmed wavelet maps for different scales.\n",
    "        realization (str): The realization identifier.\n",
    "        output_templates (dict): Dictionary of output path templates for different processing steps.\n",
    "        L_max (int): Maximum spherical harmonic degree.\n",
    "        N_directions (int): Number of directions for the directional wavelet filters.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The synthesized ILC map.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the scaling coefficients using the template path\n",
    "    f_scal = np.load(output_templates['f_scal'].format(realization=realization))\n",
    "\n",
    "    # Create the directional filters\n",
    "    filter = filters.filters_directional_vectorised(L_max, N_directions)\n",
    "\n",
    "    # Perform the synthesis to obtain the ILC map\n",
    "    MW_Pix = s2wav.synthesis(trimmed_maps, L=L_max, f_scal=f_scal, filters=filter, N=N_directions)\n",
    "\n",
    "    # Visualize the synthesized ILC map\n",
    "    title = f\"ILC CMB Map realization: {realization}\"\n",
    "    visualize_MW_Pix_map(MW_Pix, title)\n",
    "\n",
    "    # Save the synthesized ILC map\n",
    "    np.save(output_templates['synthesized_maps'].format(realization=realization), MW_Pix)\n",
    "    \n",
    "    return MW_Pix\n",
    "\n",
    "\n",
    "\n",
    "def ILC_wav_coeff_maps_MP(file_template, frequencies, scales, realizations, output_templates, L_max, N_directions, component, component_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes wavelet maps for a range of realizations, including doubling, covariance calculation,\n",
    "    matrix processing, and trimming to original resolution, using multiprocessing for efficiency\n",
    "    where tasks are independent.\n",
    "\n",
    "    Args:\n",
    "        file_template (str): Template string for file paths with placeholders for frequency, scale, and realization.\n",
    "        frequencies (list): List of frequency strings.\n",
    "        scales (list): List of scale indices.\n",
    "        realizations (list): List of realizations to process.\n",
    "        output_templates (dict): Dictionary of output path templates for different processing steps.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of trimmed maps for the final processed realization.\n",
    "    \"\"\"\n",
    "\n",
    "    synthesized_maps = []\n",
    "\n",
    "    for realization in realizations:\n",
    "        realization_str = str(realization).zfill(4)\n",
    "        print(f\"Processing realization {realization_str}\")\n",
    "        path = output_templates['trimmed_maps'].format(\n",
    "            scale=scales[0],\n",
    "            realization=realization_str,\n",
    "            component=component\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Timing for loading the original wavelet maps\n",
    "        # start_time = time.perf_counter()\n",
    "        original_wavelet_c_j = load_frequency_data(file_template, frequencies, scales, realization_str, component)\n",
    "        # load_time = time.perf_counter() - start_time\n",
    "        # print(f'Loaded original wavelet maps in {load_time:.2f} seconds')\n",
    "\n",
    "        # Timing for doubling and saving wavelet maps\n",
    "        start_time = time.perf_counter()\n",
    "        double_and_save_wavelet_maps_MP(original_wavelet_c_j, frequencies, scales, realization_str, component, output_templates['doubled_maps'])\n",
    "        double_time = time.perf_counter() - start_time\n",
    "        print(f'Doubled and saved wavelet maps in {double_time:.2f} seconds')\n",
    "\n",
    "        # loading doubled wavelet maps\n",
    "        doubled_MW_wav_c_j = load_frequency_data(output_templates['doubled_maps'], frequencies, scales, realization_str, component)\n",
    "       \n",
    "\n",
    "        # Timing for calculating covariance matrices with multiprocessing\n",
    "        start_time = time.perf_counter()\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            covariance_tasks = [\n",
    "                executor.submit(\n",
    "                    calculate_covariance_matrix_MP,\n",
    "                    frequencies, doubled_MW_wav_c_j, scale, realization_str, component, output_templates['covariance_matrices']\n",
    "                )\n",
    "                for scale in scales\n",
    "            ]\n",
    "            for future in concurrent.futures.as_completed(covariance_tasks):\n",
    "                future.result()  # Wait for all tasks to complete\n",
    "        covariance_time = time.perf_counter() - start_time\n",
    "        print(f'Calculated covariance matrices in {covariance_time:.2f} seconds')\n",
    "\n",
    "        # Timing for processing and saving matrices with multiprocessing\n",
    "        start_time = time.perf_counter()\n",
    "        F_str = '_'.join(frequencies)\n",
    "        R_covariance = [\n",
    "            np.load(output_templates['covariance_matrices'].format(component=component,\n",
    "                frequencies=F_str, scale=i, realization=realization_str))\n",
    "            for i in range(len(scales))\n",
    "        ]\n",
    "        \n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            process_tasks = [\n",
    "                executor.submit(\n",
    "                    compute_weight_vector,\n",
    "                    R_covariance[scale_idx], scale, realization_str, output_templates['weight_vector_matrices']\n",
    "                )\n",
    "                for scale_idx, scale in enumerate(scales)\n",
    "            ]\n",
    "            for future in concurrent.futures.as_completed(process_tasks):\n",
    "                future.result()  # Wait for all tasks to complete\n",
    "        process_time = time.perf_counter() - start_time\n",
    "        print(f'Calculate weight vector matrices in {process_time:.2f} seconds')\n",
    "\n",
    "        # Timing for creating ILC maps with multiprocessing\n",
    "        start_time = time.perf_counter()\n",
    "        weight_vector_load = [\n",
    "            np.load(output_templates['weight_vector_matrices'].format(component=component,\n",
    "                type=\"weight_vector\", scale=i, realization=realization_str))\n",
    "            for i in range(len(scales))\n",
    "        ]\n",
    "\n",
    "        ####################\n",
    "        # Unused code for creating doubled ILC map: multiprocessing is slow \n",
    "        # with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        #     # Submit tasks for each scale to be processed in parallel\n",
    "        #     futures = [\n",
    "        #         executor.submit(\n",
    "        #             create_doubled_ILC_map,\n",
    "        #             frequencies, scale, weight_vector_load, doubled_MW_wav_c_j, realization_str, output_templates['ilc_maps']\n",
    "        #         )\n",
    "        #         for scale in scales\n",
    "        #     ]\n",
    "            \n",
    "        #     # Collect the results as they complete\n",
    "        #     doubled_maps = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "    \n",
    "        #####################\n",
    "        \n",
    "        doubled_maps = []\n",
    "        for i in range(len(scales)):\n",
    "            doubled_maps.append(create_doubled_ILC_map(frequencies, scales[i], weight_vector_load, doubled_MW_wav_c_j, realization=realization_str))\n",
    "\n",
    "        #doubled_maps = [np.load(f\"ILC/ILC_doubled_maps/ILC_Map_S{i}_R{realization_str}_MP.npy\") for i in range(len(scales))]\n",
    "        # If you saved UNconstrained (no 'cilc'):\n",
    "        doubled_maps = [\n",
    "            np.load(f\"ILC/ILC_doubled_maps/ILC_Map_{component}_S{scale}_R{realization_str}_MP.npy\")\n",
    "            for scale in scales\n",
    "        ]\n",
    "\n",
    "        ilc_time = time.perf_counter() - start_time\n",
    "        print(f'Created ILC maps in {ilc_time:.2f} seconds')\n",
    "\n",
    "        # Load the ILC maps\n",
    "        doubled_maps = [np.load(output_templates['ilc_maps'].format(scale=i, realization=realization_str)) for i in range(len(scales))]\n",
    "\n",
    "        # Timing for trimming to original resolution with multiprocessing\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(trim_to_original, doubled_maps[scale], scale, realization_str, component, component_name, output_templates['trimmed_maps'])\n",
    "                for scale in scales\n",
    "            ]\n",
    "            trimmed_maps = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "        trim_time = time.perf_counter() - start_time\n",
    "        print(f'Trimmed maps to original resolution in {trim_time:.2f} seconds')\n",
    "\n",
    "        # Timing for visualizing wavelet coefficient maps\n",
    "        start_time = time.perf_counter()\n",
    "        for scale in scales:\n",
    "            title = \"ILC Wavelet coefficient map at scale: \"\n",
    "            visualize_MW_Pix_map(trimmed_maps[scale], title + str(scale))\n",
    "        visualize_time = time.perf_counter() - start_time\n",
    "        print(f'Visualized wavelet coefficient maps in {visualize_time:.2f} seconds')\n",
    "        \n",
    "\n",
    "        # Synthesize the ILC map from the trimmed maps\n",
    "        synthesized_map = synthesize_ILC_maps(trimmed_maps, realization_str, output_templates, L_max, N_directions)\n",
    "        synthesized_maps.append(synthesized_map)\n",
    "        \n",
    "\n",
    "    return synthesized_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d5b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\n",
      " [[ 1.     1.    -2.   ]\n",
      " [ 0.875  1.    -1.5  ]\n",
      " [ 0.75   1.    -1.   ]\n",
      " [ 0.625  1.    -0.5  ]\n",
      " [ 0.5    1.     0.   ]\n",
      " [ 0.375  1.     0.5  ]\n",
      " [ 0.25   1.     1.   ]\n",
      " [ 0.125  1.     1.5  ]\n",
      " [ 0.     1.     2.   ]]\n",
      "f for cmb: [0. 1. 0.]\n",
      "f for tsz: [0. 0. 1.]\n",
      "f for sync: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example spectral response vectors\n",
    "a = np.ones(9)                   # CMB\n",
    "b = np.linspace(-2, 2, 9)         # tSZ\n",
    "c = np.linspace(1, 0, 9)          # Sync\n",
    "\n",
    "# Build F in arbitrary order\n",
    "F = np.column_stack([c, a, b])    # order changed: Sync, CMB, tSZ\n",
    "\n",
    "# Store known spectral responses in a dict\n",
    "reference_vectors = {\n",
    "    \"cmb\": a,\n",
    "    \"tsz\": b,\n",
    "    \"sync\": c\n",
    "}\n",
    "\n",
    "def build_f(F, component_name):\n",
    "    \"\"\"Return constraint vector f for given component_name based on column match in F.\"\"\"\n",
    "    target_vec = reference_vectors[component_name.lower()]\n",
    "    for col_idx in range(F.shape[1]):\n",
    "        if np.allclose(F[:, col_idx] / np.linalg.norm(F[:, col_idx]),\n",
    "                       target_vec / np.linalg.norm(target_vec)):\n",
    "            f = np.zeros(F.shape[1])\n",
    "            f[col_idx] = 1\n",
    "            return f\n",
    "    raise ValueError(f\"Component '{component_name}' not found in F.\")\n",
    "\n",
    "# Test\n",
    "print(\"F:\\n\", F)\n",
    "print(\"f for cmb:\", build_f(F, \"cmb\"))\n",
    "print(\"f for tsz:\", build_f(F, \"tsz\"))\n",
    "print(\"f for sync:\", build_f(F, \"sync\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008344a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f= [[1]\n",
      " [0]\n",
      " [0]]\n",
      "Step 1: Fᵗ R⁻¹ =\n",
      " [[1.         0.5        0.33333333]\n",
      " [0.         0.5        0.33333333]\n",
      " [0.         0.         0.33333333]]\n",
      "\n",
      "Step 2: Fᵗ R⁻¹ F =\n",
      " [[1.83333333 0.83333333 0.33333333]\n",
      " [0.83333333 0.83333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n",
      "\n",
      "Step 3: (Fᵗ R⁻¹ F)⁻¹ =\n",
      " [[ 1.00000000e+00 -1.00000000e+00 -1.21115239e-16]\n",
      " [-1.00000000e+00  3.00000000e+00 -2.00000000e+00]\n",
      " [-2.01858732e-17 -2.00000000e+00  5.00000000e+00]]\n",
      "\n",
      "Step 4b: (Fᵗ R⁻¹ F)⁻¹ f =\n",
      " [[ 1.00000000e+00]\n",
      " [-1.00000000e+00]\n",
      " [-2.01858732e-17]]\n",
      "\n",
      "Step 5: F (Fᵗ R⁻¹ F)⁻¹ f =\n",
      " [[ 1.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-2.01858732e-17]]\n",
      "\n",
      "Step 6: Final weight vector w =\n",
      " [[ 1.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-6.72862439e-18]]\n",
      "\n",
      "Step 7: Fᵗ w =\n",
      " [[ 1.00000000e+00]\n",
      " [-6.72862439e-18]\n",
      " [-6.72862439e-18]]\n",
      "\n",
      "Step 7 check: Constraint satisfied (Fᵗ w = f_col) ? True\n",
      "f= [[1]\n",
      " [0]]\n",
      "Step 1: Fᵗ R⁻¹ =\n",
      " [[0.5        0.33333333 0.25       0.2       ]\n",
      " [0.         0.33333333 0.5        0.6       ]]\n",
      "\n",
      "Step 2: Fᵗ R⁻¹ F =\n",
      " [[1.28333333 1.43333333]\n",
      " [1.43333333 3.13333333]]\n",
      "\n",
      "Step 3: (Fᵗ R⁻¹ F)⁻¹ =\n",
      " [[ 1.59322034 -0.72881356]\n",
      " [-0.72881356  0.65254237]]\n",
      "\n",
      "Step 4: (Fᵗ R⁻¹ F)⁻¹ f =\n",
      " [[ 1.59322034]\n",
      " [-0.72881356]]\n",
      "\n",
      "Step 5: F (Fᵗ R⁻¹ F)⁻¹ f =\n",
      " [[ 1.59322034]\n",
      " [ 0.86440678]\n",
      " [ 0.13559322]\n",
      " [-0.59322034]]\n",
      "\n",
      "Step 6: Final weight vector w =\n",
      " [[ 0.79661017]\n",
      " [ 0.28813559]\n",
      " [ 0.03389831]\n",
      " [-0.11864407]]\n",
      "\n",
      "Step 7: Fᵗ w =\n",
      " [[ 1.00000000e+00]\n",
      " [-1.11022302e-16]]\n",
      "\n",
      "Step 7 check: Constraint satisfied (Fᵗ w = f_col) ? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define simple integer inputs\n",
    "R = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 2, 0],\n",
    "    [0, 0, 3]\n",
    "])  # Diagonal covariance matrix (3x3)\n",
    "\n",
    "F = np.array([\n",
    "    [1, 0, 0],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1]\n",
    "])  # Spectral response matrix (3x3)\n",
    "\n",
    "f = np.array([1, 0, 0])  # Constraint vector (3,)\n",
    "f = f.reshape((F.shape[1], 1))\n",
    "print ('f=', f)\n",
    "\n",
    "# Step 1: Fᵗ R⁻¹\n",
    "R_inv = np.linalg.inv(R)\n",
    "FT_Rinv = np.dot(F.T, R_inv)\n",
    "print(\"Step 1: Fᵗ R⁻¹ =\\n\", FT_Rinv)\n",
    "\n",
    "# Step 2: Fᵗ R⁻¹ F\n",
    "constraint_matrix = np.dot(FT_Rinv, F)\n",
    "print(\"\\nStep 2: Fᵗ R⁻¹ F =\\n\", constraint_matrix)\n",
    "\n",
    "# Step 3: (Fᵗ R⁻¹ F)⁻¹\n",
    "constraint_matrix_inv = np.linalg.inv(constraint_matrix)\n",
    "print(\"\\nStep 3: (Fᵗ R⁻¹ F)⁻¹ =\\n\", constraint_matrix_inv)\n",
    "\n",
    "# Step 4: (Fᵗ R⁻¹ F)⁻¹ f\n",
    "temp = np.dot(constraint_matrix_inv, f)\n",
    "print(\"\\nStep 4b: (Fᵗ R⁻¹ F)⁻¹ f =\\n\", temp)\n",
    "\n",
    "# Step 5: F (Fᵗ R⁻¹ F)⁻¹ f\n",
    "F_temp = np.dot(F, temp)\n",
    "print(\"\\nStep 5: F (Fᵗ R⁻¹ F)⁻¹ f =\\n\", F_temp)\n",
    "\n",
    "# Step 6: Final weight vector\n",
    "w = np.dot(R_inv, F_temp)\n",
    "print(\"\\nStep 6: Final weight vector w =\\n\", w)\n",
    "\n",
    "# Step 7: Verify constraint Fᵗ w = f\n",
    "FT_w = np.dot(F.T, w)\n",
    "print(\"\\nStep 7: Fᵗ w =\\n\", FT_w)\n",
    "print(\"\\nStep 7 check: Constraint satisfied (Fᵗ w = f_col) ?\", np.allclose(FT_w, f))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define integer-valued 4x4 covariance matrix (4 frequency channels)\n",
    "R = np.array([\n",
    "    [2, 0, 0, 0],\n",
    "    [0, 3, 0, 0],\n",
    "    [0, 0, 4, 0],\n",
    "    [0, 0, 0, 5]\n",
    "])  # (4x4)\n",
    "\n",
    "# Define spectral response matrix: 4 freq channels × 2 components\n",
    "F = np.array([\n",
    "    [1, 0],    # Channel 1: only component 1\n",
    "    [1, 1],    # Channel 2: mix of both\n",
    "    [1, 2],    # Channel 3: stronger component 2\n",
    "    [1, 3]     # Channel 4: even stronger component 2\n",
    "])  # (4x2)\n",
    "\n",
    "# Define constraint vector for extracting component 1\n",
    "f = np.array([1, 0])  # We want to preserve only the first component\n",
    "f = f.reshape((F.shape[1], 1))  # Reshape to (2,1)\n",
    "print ('f=', f)\n",
    "\n",
    "# Step 1: Fᵗ R⁻¹\n",
    "R_inv = np.linalg.inv(R)\n",
    "FT_Rinv = np.dot(F.T, R_inv)\n",
    "print(\"Step 1: Fᵗ R⁻¹ =\\n\", FT_Rinv)\n",
    "\n",
    "# Step 2: Fᵗ R⁻¹ F\n",
    "constraint_matrix = np.dot(FT_Rinv, F)\n",
    "print(\"\\nStep 2: Fᵗ R⁻¹ F =\\n\", constraint_matrix)\n",
    "\n",
    "# Step 3: (Fᵗ R⁻¹ F)⁻¹\n",
    "constraint_matrix_inv = np.linalg.inv(constraint_matrix)\n",
    "print(\"\\nStep 3: (Fᵗ R⁻¹ F)⁻¹ =\\n\", constraint_matrix_inv)\n",
    "\n",
    "# Step 4: (Fᵗ R⁻¹ F)⁻¹ f\n",
    "temp = np.dot(constraint_matrix_inv, f)\n",
    "print(\"\\nStep 4: (Fᵗ R⁻¹ F)⁻¹ f =\\n\", temp)\n",
    "\n",
    "# Step 5: F (Fᵗ R⁻¹ F)⁻¹ f\n",
    "F_temp = np.dot(F, temp)\n",
    "print(\"\\nStep 5: F (Fᵗ R⁻¹ F)⁻¹ f =\\n\", F_temp)\n",
    "\n",
    "# Step 6: Final weight vector\n",
    "w = np.dot(R_inv, F_temp)\n",
    "print(\"\\nStep 6: Final weight vector w =\\n\", w)\n",
    "\n",
    "# Step 7: Verify constraint Fᵗ w = f\n",
    "FT_w = np.dot(F.T, w)\n",
    "print(\"\\nStep 7: Fᵗ w =\\n\", FT_w)\n",
    "print(\"\\nStep 7 check: Constraint satisfied (Fᵗ w = f_col) ?\", np.allclose(FT_w, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b940ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component_names (column order): ['tsz', 'sync', 'cmb']\n",
      "Selected targets: ['cmb','tsz']\n",
      "Constraint vector f (aligned to component_names order): [1. 0. 1.]\n",
      "Matched column indices: [2, 0]\n",
      "\n",
      "Step 1: Fᵗ R⁻¹ =\n",
      " [[1.         0.5        0.33333333]\n",
      " [0.         0.5        0.33333333]\n",
      " [0.         0.         0.33333333]]\n",
      "\n",
      "Step 2: Fᵗ R⁻¹ F =\n",
      " [[1.83333333 0.83333333 0.33333333]\n",
      " [0.83333333 0.83333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n",
      "\n",
      "Step 3: (Fᵗ R⁻¹ F)⁻¹ =\n",
      " [[ 1.00000000e+00 -1.00000000e+00 -1.21115239e-16]\n",
      " [-1.00000000e+00  3.00000000e+00 -2.00000000e+00]\n",
      " [-2.01858732e-17 -2.00000000e+00  5.00000000e+00]]\n",
      "\n",
      "Step 4: (Fᵗ R⁻¹ F)⁻¹ f =\n",
      " [[ 1.]\n",
      " [-3.]\n",
      " [ 5.]]\n",
      "\n",
      "Step 5: F (Fᵗ R⁻¹ F)⁻¹ f =\n",
      " [[ 1.]\n",
      " [-2.]\n",
      " [ 3.]]\n",
      "\n",
      "Step 6: Final weight vector w =\n",
      " [ 1. -1.  1.]\n",
      "\n",
      "Step 7: Fᵗ w =\n",
      " [1. 0. 1.]\n",
      "\n",
      "Constraint satisfied? -> True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----- Toy inputs (same F and R) -----\n",
    "R = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 2, 0],\n",
    "    [0, 0, 3]\n",
    "])  # Diagonal covariance matrix (3x3)\n",
    "\n",
    "F = np.array([\n",
    "    [1, 0, 0],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1]\n",
    "])  # Spectral response matrix (3x3)\n",
    "\n",
    "# ----- NEW: robust, order-agnostic name -> column mapping -----\n",
    "def find_f_from_names(component_names, selected):\n",
    "    \"\"\"\n",
    "    Build constraint vector f purely from name->column mapping,\n",
    "    independent of where components sit in F.\n",
    "    \"\"\"\n",
    "    if isinstance(selected, (str, bytes)):\n",
    "        selected = [selected]\n",
    "    names_lower = [n.lower() for n in component_names]\n",
    "    f = np.zeros(len(component_names), dtype=float)\n",
    "    idxs = []\n",
    "    for name in selected:\n",
    "        try:\n",
    "            idx = names_lower.index(name.lower())\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"{name} not in component_names={component_names}\")\n",
    "        f[idx] = 1.0\n",
    "        idxs.append(idx)\n",
    "    return f, idxs\n",
    "\n",
    "# Example: arbitrary order of columns\n",
    "component_names = [\"tsz\", \"sync\", \"cmb\"]  # means: col0=tsz, col1=sync, col2=cmb\n",
    "\n",
    "# Build f for \"cmb + tsz\" irrespective of where they are in F\n",
    "f, matched = find_f_from_names(component_names, [\"cmb\", \"tsz\"])  # expect f = [1,0,1]\n",
    "print(\"component_names (column order):\", component_names)\n",
    "print(\"Selected targets: ['cmb','tsz']\")\n",
    "print(\"Constraint vector f (aligned to component_names order):\", f)\n",
    "print(\"Matched column indices:\", matched)\n",
    "\n",
    "# ---- Your exact step-by-step algebra ----\n",
    "# Step 1: Fᵗ R⁻¹\n",
    "R_inv = np.linalg.inv(R)\n",
    "FT_Rinv = np.dot(F.T, R_inv)\n",
    "print(\"\\nStep 1: Fᵗ R⁻¹ =\\n\", FT_Rinv)\n",
    "\n",
    "# Step 2: Fᵗ R⁻¹ F\n",
    "constraint_matrix = np.dot(FT_Rinv, F)\n",
    "print(\"\\nStep 2: Fᵗ R⁻¹ F =\\n\", constraint_matrix)\n",
    "\n",
    "# Step 3: (Fᵗ R⁻¹ F)⁻¹\n",
    "constraint_matrix_inv = np.linalg.inv(constraint_matrix)\n",
    "print(\"\\nStep 3: (Fᵗ R⁻¹ F)⁻¹ =\\n\", constraint_matrix_inv)\n",
    "\n",
    "# Step 4: (Fᵗ R⁻¹ F)⁻¹ f\n",
    "temp = np.dot(constraint_matrix_inv, f.reshape(-1, 1))  # column vector\n",
    "print(\"\\nStep 4: (Fᵗ R⁻¹ F)⁻¹ f =\\n\", temp)\n",
    "\n",
    "# Step 5: F (Fᵗ R⁻¹ F)⁻¹ f\n",
    "F_temp = np.dot(F, temp)\n",
    "print(\"\\nStep 5: F (Fᵗ R⁻¹ F)⁻¹ f =\\n\", F_temp)\n",
    "\n",
    "# Step 6: Final weight vector\n",
    "w = np.dot(R_inv, F_temp)        # (3,1)\n",
    "w_vec = w.ravel()                # flatten to (3,)\n",
    "print(\"\\nStep 6: Final weight vector w =\\n\", w_vec)\n",
    "\n",
    "# Step 7: Verify constraint Fᵗ w = f\n",
    "FT_w = np.dot(F.T, w_vec)\n",
    "print(\"\\nStep 7: Fᵗ w =\\n\", FT_w)\n",
    "print(\"\\nConstraint satisfied? ->\", np.allclose(FT_w, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddaeb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (CMB): [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "b (tSZ): [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.18225885e-01\n",
      " -8.15581790e-02 -6.09521620e-04  1.75660570e-01  4.38851414e-01\n",
      "  8.69438516e-01]\n",
      "c (sync): [0.86775717 0.27183924 0.06948647 0.02611258 0.01107374 0.00549842\n",
      " 0.00524893 0.01690708 0.40880854]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Physical constants ---\n",
    "h = 6.62607015e-34       # Planck constant [J·s]\n",
    "k = 1.380649e-23         # Boltzmann constant [J/K]\n",
    "T_cmb = 2.7255           # CMB temperature [K]\n",
    "c = 299792458            # Speed of light [m/s]\n",
    "\n",
    "# --- Planck frequency channels in GHz ---\n",
    "frequencies = ['030', '044', '070', '100', '143', '217', '353', '545', '857']\n",
    "freqs_GHz = np.array([float(f) for f in frequencies])\n",
    "nu = freqs_GHz * 1e9     # Convert GHz to Hz\n",
    "x = h * nu / (k * T_cmb) # Dimensionless frequency\n",
    "\n",
    "# --- Unit conversion factor from thermodynamic to brightness temp ---\n",
    "g_nu = (x**2 * np.exp(x)) / (np.exp(x) - 1)**2\n",
    "\n",
    "# --- (a) CMB: constant across frequencies in thermodynamic units ---\n",
    "a = np.ones_like(nu)\n",
    "\n",
    "# --- (b) tSZ: thermal SZ effect frequency dependence ---\n",
    "fx = x * ((np.exp(x) + 1) / (np.exp(x) - 1)) - 4\n",
    "# Zero out known nulls (no tSZ expected at these bands)\n",
    "no_tsz_freqs = {'030', '044', '070'}\n",
    "fx = np.array([fx[i] if frequencies[i] not in no_tsz_freqs else 0 for i in range(len(frequencies))])\n",
    "# Normalize in thermodynamic units\n",
    "b = fx / np.linalg.norm(fx)\n",
    "\n",
    "# --- (c) Synchrotron: assume power law with β_s = -3.1 in brightness temp ---\n",
    "beta_s = -3.1\n",
    "nu0 = 30e9  # reference frequency (30 GHz)\n",
    "T_sync_ant = (nu / nu0) ** beta_s\n",
    "# Convert synchrotron to thermodynamic temp\n",
    "T_sync_thermo = T_sync_ant / g_nu\n",
    "# Normalize\n",
    "c = T_sync_thermo / np.linalg.norm(T_sync_thermo)\n",
    "\n",
    "# --- Output ---\n",
    "print(\"a (CMB):\", a)\n",
    "print(\"b (tSZ):\", b)\n",
    "print(\"c (sync):\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a7ff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: [[ 1.00000000e+00  0.00000000e+00  8.67757169e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  2.71839240e-01]\n",
      " [ 1.00000000e+00  0.00000000e+00  6.94864702e-02]\n",
      " [ 1.00000000e+00 -1.18225885e-01  2.61125772e-02]\n",
      " [ 1.00000000e+00 -8.15581790e-02  1.10737419e-02]\n",
      " [ 1.00000000e+00 -6.09521620e-04  5.49841744e-03]\n",
      " [ 1.00000000e+00  1.75660570e-01  5.24893397e-03]\n",
      " [ 1.00000000e+00  4.38851414e-01  1.69070773e-02]\n",
      " [ 1.00000000e+00  8.69438516e-01  4.08808544e-01]]\n",
      "Component 'CMB' matched at column 0\n",
      "f: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "components = {\n",
    "    'CMB': a,\n",
    "    'tSZ': b,\n",
    "    'sync': c,\n",
    "}\n",
    "\n",
    "F = np.stack([a, b, c], axis=1)  # F is (N_freq, N_comp)\n",
    "print('F:', F)\n",
    "\n",
    "def get_constraint_vector(F, name, components):\n",
    "    target_vec = components[name]\n",
    "    for i in range(F.shape[1]):\n",
    "        if np.allclose(F[:, i], target_vec):\n",
    "            f = np.zeros(F.shape[1])\n",
    "            f[i] = 1.0\n",
    "            print(f\"Component '{name}' matched at column {i}\")\n",
    "            return f\n",
    "    raise ValueError(f\"Component vector for '{name}' not found in F.\")\n",
    "\n",
    "f = get_constraint_vector(F, 'CMB', components)\n",
    "print ('f:',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb39015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from s2wav import synthesis\n",
    "\n",
    "# Store known spectral responses in a dict\n",
    "# You must define these reference vectors before calling compute_weight_vector\n",
    "reference_vectors = {\n",
    "    \"cmb\": a,   # column 0 of F\n",
    "    \"tsz\": b,   # column 1 of F\n",
    "    \"sync\": c   # column 2 of F\n",
    "}\n",
    "\n",
    "def normalize_targets(component_name):\n",
    "    \"\"\"Return (list_of_names, tag_string) for filenames.\"\"\"\n",
    "    if isinstance(component_name, (list, tuple, np.ndarray)):\n",
    "        names = [str(n) for n in component_name]\n",
    "    elif component_name is None:\n",
    "        names = []\n",
    "    else:\n",
    "        names = [str(component_name)]\n",
    "    tag = \"+\".join(names) if names else \"none\"\n",
    "    return names, tag\n",
    "\n",
    "def find_f_from_component_name(F, component_name_or_names, allow_sign_flip=False, atol=1e-8):\n",
    "    \"\"\"\n",
    "    Build f with 1.0 at the columns in F that match the reference vectors by direction.\n",
    "    Accepts a string or a list/tuple of names (e.g., [\"cmb\",\"tsz\"]).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    if isinstance(component_name_or_names, (str, bytes)):\n",
    "        names = [component_name_or_names]\n",
    "    else:\n",
    "        names = list(component_name_or_names)\n",
    "\n",
    "    N_comp = F.shape[1]\n",
    "    f = np.zeros(N_comp, dtype=float)\n",
    "\n",
    "    for name in names:\n",
    "        target_vec = reference_vectors[name.lower()]\n",
    "        if target_vec is None:\n",
    "            raise ValueError(f\"Reference vector for '{name}' not set in reference_vectors.\")\n",
    "        t = target_vec / np.linalg.norm(target_vec)\n",
    "\n",
    "        matched = False\n",
    "        for j in range(N_comp):\n",
    "            col = F[:, j] / np.linalg.norm(F[:, j])\n",
    "            if np.allclose(col, t, atol=atol) or (allow_sign_flip and np.allclose(col, -t, atol=atol)):\n",
    "                # If sign-flipped, set -1.0 so the effective gain on the reference is +1\n",
    "                f[j] = -1.0 if (allow_sign_flip and np.allclose(col, -t, atol=atol)) else 1.0\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            raise ValueError(f\"Component '{name}' not found in F.\")\n",
    "    return f\n",
    "\n",
    "\n",
    "def compute_weight_vector(R, scale, realization, weight_vector_matrix_template,\n",
    "                          component, component_name,\n",
    "                          constraint=False, F=None, f=None):\n",
    "    \"\"\"\n",
    "    Computes weight vectors from a covariance matrix R using either standard or generalized ILC.\n",
    "\n",
    "    Args:\n",
    "        R (np.ndarray): Input covariance matrix. Shape (N_freq, N_freq) or (n1, n2, N_freq, N_freq).\n",
    "        scale (int): Scale index for saving purposes.\n",
    "        realization (str): Realization identifier string.\n",
    "        weight_vector_matrix_template (str): Template for saving the computed weights.\n",
    "        constraint (bool): Whether to use constrained ILC.\n",
    "        F (np.ndarray): Spectral response matrix of shape (N_freq, N_comp), required if constraint=True.\n",
    "        f (np.ndarray): Constraint vector of shape (N_comp,), required if constraint=True.\n",
    "\n",
    "    Returns:\n",
    "        inverses (np.ndarray): Inverse covariance matrices.\n",
    "        weight_vectors (np.ndarray): Weight vectors.\n",
    "        singular_matrices_location (list): List of (i, j) indices where matrix inversion failed.\n",
    "    \"\"\"\n",
    "    if R.ndim == 4:\n",
    "        R_Pix = np.swapaxes(np.swapaxes(R, 0, 2), 1, 3)\n",
    "        dim1, dim2 = R_Pix.shape[:2]\n",
    "        subdim1, subdim2 = R_Pix.shape[2:]\n",
    "    elif R.ndim == 2:\n",
    "        R_Pix = R\n",
    "        dim1, dim2 = 1, 1\n",
    "        subdim1, subdim2 = R_Pix.shape\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected array dimension: {R.ndim}\")\n",
    "\n",
    "    if constraint:\n",
    "        N_freq, N_comp = F.shape\n",
    "        \n",
    "        # --- Automatically set f from component_name if given ---\n",
    "        if f is None and component_name is not None:\n",
    "            f, _ = find_f_from_component_name(F, component_name)\n",
    "        # -------------------------------------------------------------\n",
    "        assert f is not None, \"Constraint vector f must be provided when constraint=True\"\n",
    "        assert f.shape == (N_comp,), f\"Constraint vector f must have shape ({N_comp},)\"\n",
    "    else:\n",
    "        # --- Use component_name also for unconstrained ILC ---\n",
    "        if component_name is None:\n",
    "            raise ValueError(\"component_name must be provided when constraint=False\")\n",
    "        _, component_index = find_f_from_component_name(F, component_name)\n",
    "        N_freq = subdim2\n",
    "        identity_vector = np.zeros(N_freq)\n",
    "        identity_vector[component_index] = 1.0\n",
    "        # ----------------------------------------------------------\n",
    "\n",
    "    inverses = np.zeros((dim1, dim2, subdim1, subdim2)) if R.ndim == 4 else np.zeros((subdim1, subdim2))\n",
    "    weight_vectors = np.zeros((dim1, dim2, subdim1)) if R.ndim == 4 else np.zeros(subdim1)\n",
    "    singular_matrices_location = []\n",
    "\n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            try:\n",
    "                R_inv = np.linalg.inv(R_Pix[i, j] if R.ndim == 4 else R_Pix)\n",
    "\n",
    "                if constraint:\n",
    "                    # Step 1: Fᵗ R⁻¹\n",
    "                    FT_Rinv = np.dot(F.T, R_inv)                  # (N_comp, N_freq)\n",
    "                    # Step 2: Fᵗ R⁻¹ F\n",
    "                    constraint_matrix = np.dot(FT_Rinv, F)        # (N_comp, N_comp)\n",
    "                    # Step 3: (Fᵗ R⁻¹ F)⁻¹\n",
    "                    constraint_matrix_inv = np.linalg.inv(constraint_matrix)\n",
    "\n",
    "                    # Step 4: reshape f for matrix multiplication\n",
    "                    f_vec = f.reshape((F.shape[1], 1))  # [1,0,0] -----> [[1],\n",
    "                                                        #                 [0],\n",
    "                                                        #                 [0]]\n",
    "                    temp = np.dot(constraint_matrix_inv, f_vec)\n",
    "                    # Step 5: F (Fᵗ R⁻¹ F)⁻¹ f\n",
    "                    F_temp = np.dot(F, temp)\n",
    "                    # Step 6: Final weight vector\n",
    "                    w = np.dot(R_inv, F_temp).T\n",
    "                else:\n",
    "                    numerator = np.dot(R_inv, identity_vector)\n",
    "                    denominator = np.dot(numerator, identity_vector)\n",
    "                    w = numerator / denominator\n",
    "\n",
    "                if R.ndim == 4:\n",
    "                    inverses[i, j] = R_inv\n",
    "                    weight_vectors[i, j] = w\n",
    "                else:\n",
    "                    inverses = R_inv\n",
    "                    weight_vectors = w\n",
    "\n",
    "            except np.linalg.LinAlgError:\n",
    "                singular_matrices_location.append((i, j))\n",
    "                singular_matrix_path = weight_vector_matrix_template.format(\n",
    "                    component=component,\n",
    "                    component_name=component_name,\n",
    "                    scale=scale,\n",
    "                    realization=realization\n",
    "                ).replace(\".npy\", f\"_singular_{i}_{j}.npy\")\n",
    "                np.save(singular_matrix_path, R_Pix[i, j] if R.ndim == 4 else R_Pix)\n",
    "                if R.ndim == 4:\n",
    "                    weight_vectors[i, j] = np.zeros(N_freq)\n",
    "                else:\n",
    "                    weight_vectors = np.zeros(N_freq)\n",
    "\n",
    "    # Save final weight vector matrix\n",
    "    np.save(\n",
    "        weight_vector_matrix_template.format(\n",
    "            component=component,\n",
    "            component_name=component_name,\n",
    "            scale=scale,\n",
    "            realization=realization\n",
    "        ),\n",
    "        weight_vectors\n",
    "    )\n",
    "\n",
    "    return inverses, weight_vectors, singular_matrices_location, component_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7f36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ILC_for_pixel(i, j, frequencies, scale, weight_vector_load, doubled_MW_wav_c_j):\n",
    "    pix_vector = np.array([\n",
    "        doubled_MW_wav_c_j[(frequencies[k], scale)][i, j] for k in range(len(frequencies))\n",
    "    ])\n",
    "    return np.dot(weight_vector_load[i, j], pix_vector)\n",
    "\n",
    "def create_doubled_ILC_map(frequencies, scale, weight_vector_load, doubled_MW_wav_c_j, realization, constraint=False, component=None, component_name=None):\n",
    "    size = doubled_MW_wav_c_j[(frequencies[0], scale)].shape\n",
    "    doubled_map = np.zeros((size[0], size[1]))\n",
    "\n",
    "    for i in range(doubled_map.shape[0]):\n",
    "        for j in range(doubled_map.shape[1]):\n",
    "            doubled_map[i, j] = compute_ILC_for_pixel(i, j, frequencies, scale, weight_vector_load, doubled_MW_wav_c_j)\n",
    "\n",
    "    if constraint:\n",
    "        path = f\"ILC/ILC_doubled_maps/ILC_Map_{component}_cilc_{component_name}_S{scale}_R{realization}_MP.npy\"\n",
    "    else:\n",
    "        path = f\"ILC/ILC_doubled_maps/ILC_Map_{component}_S{scale}_R{realization}_MP.npy\"\n",
    "\n",
    "    np.save(path, doubled_map)\n",
    "    return doubled_map\n",
    "\n",
    "def synthesize_ILC_maps_generalised(\n",
    "    trimmed_maps, realization, output_templates,\n",
    "    L_max, N_directions,\n",
    "    component=None, component_name=None, constraint=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Synthesizes full-sky ILC or cILC map from trimmed wavelet coefficient maps.\n",
    "\n",
    "    Args:\n",
    "        trimmed_maps (list): Trimmed wavelet maps across scales.\n",
    "        realization (str): Realization string (e.g., '0000').\n",
    "        output_templates (dict): Output file templates.\n",
    "        L_max (int): Maximum spherical harmonic degree.\n",
    "        N_directions (int): Number of wavelet directions.\n",
    "        component_name (str or None): Component name for constrained ILC (e.g., 'cmb').\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Final synthesized ILC map.\n",
    "    \"\"\"\n",
    "    f_scal = np.load(output_templates['f_scal'].format(\n",
    "    component=component,\n",
    "    realization=realization))\n",
    "\n",
    "    filter_bank = filters.filters_directional_vectorised(L_max, N_directions)\n",
    "    MW_Pix = synthesis(trimmed_maps, L=L_max, f_scal=f_scal, filters=filter_bank, N=N_directions)\n",
    "\n",
    "    # Title and filename\n",
    "    prefix = \"cILC\" if component_name else \"ILC\"\n",
    "    name = component_name.upper() if component_name else \"\"\n",
    "    title = f\"{prefix} {name} Map | realization: {realization}\".strip()\n",
    "\n",
    "    # Minimal fix: format filename with component and component_name\n",
    "    filename = output_templates['synthesized_maps'].format(\n",
    "        component=component,\n",
    "        component_name=component_name,\n",
    "        realization=realization\n",
    "    )\n",
    "\n",
    "    visualize_MW_Pix_map(MW_Pix, title)\n",
    "    np.save(filename, MW_Pix)\n",
    "    return MW_Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1373db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import numpy as np\n",
    "\n",
    "def ILC_wav_coeff_maps_MP(\n",
    "    file_template, frequencies, scales, realizations,\n",
    "    output_templates, L_max, N_directions,\n",
    "    component,\n",
    "    constraint=False, F=None, component_name=None):\n",
    "\n",
    "    # ---- one-shot checker: verify F^T w = f once ----\n",
    "    def _check_against_F(W, F, f, tol=1e-6):\n",
    "        W = np.asarray(W)\n",
    "        if W.ndim == 2 and 1 in W.shape:   # (1,Nf) or (Nf,1) -> (Nf,)\n",
    "            W = W.reshape(-1)\n",
    "        resp = np.tensordot(W, F, axes=([-1], [0]))  # (..., N_comp)\n",
    "        ok = np.allclose(resp, f, atol=tol, rtol=0.0)\n",
    "        print(\"FINAL CHECK  F^T w == f  ->\", ok)\n",
    "        if not ok:\n",
    "            print(\"max |F^T w - f| =\", float(np.max(np.abs(resp - f))))\n",
    "        return ok\n",
    "\n",
    "    synthesized_maps = []\n",
    "\n",
    "    # --- Prepare constraint vector / tags ---\n",
    "    if constraint:\n",
    "        if F is None or component_name is None:\n",
    "            raise ValueError(\"Must provide F and component_name if constraint=True\")\n",
    "        target_names, component_name_tag = normalize_targets(component_name)\n",
    "        if len(target_names) == 0:\n",
    "            raise ValueError(\"Provide at least one target component name when constraint=True\")\n",
    "        f = find_f_from_component_name(F, target_names, allow_sign_flip=True)\n",
    "    else:\n",
    "        if isinstance(component_name, (list, tuple, np.ndarray)):\n",
    "            raise ValueError(\"For unconstrained ILC, pass a single component_name (e.g., 'cmb').\")\n",
    "        target_names, component_name_tag = normalize_targets(component_name)\n",
    "        f = None  # not used in unconstrained\n",
    "\n",
    "    for realization in realizations:\n",
    "        realization_str = str(realization).zfill(4)\n",
    "        print(f\"Processing realization {realization_str} for component {component}\")\n",
    "\n",
    "        # 1) Load original wavelet maps\n",
    "        original_wavelet_c_j = load_frequency_data(\n",
    "            file_template, frequencies, scales, realization_str, component\n",
    "        )\n",
    "\n",
    "        # 2) Double resolution and save\n",
    "        double_and_save_wavelet_maps_MP(\n",
    "            original_wavelet_c_j, frequencies, scales, realization_str,\n",
    "            component, output_templates['doubled_maps']\n",
    "        )\n",
    "\n",
    "        # 3) Load doubled resolution wavelet maps\n",
    "        doubled_MW_wav_c_j = load_frequency_data(\n",
    "            output_templates['doubled_maps'], frequencies, scales, realization_str, component\n",
    "        )\n",
    "\n",
    "        # 4) Compute covariance matrices (parallel over scales)\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(\n",
    "                    calculate_covariance_matrix_MP,\n",
    "                    frequencies, doubled_MW_wav_c_j, scale,\n",
    "                    realization_str, component,\n",
    "                    output_templates['covariance_matrices']\n",
    "                )\n",
    "                for scale in scales\n",
    "            ]\n",
    "            for fut in concurrent.futures.as_completed(futures):\n",
    "                fut.result()\n",
    "\n",
    "        # 5) Load covariance matrices\n",
    "        F_str = '_'.join(frequencies)\n",
    "        R_covariance = [\n",
    "            np.load(output_templates['covariance_matrices'].format(\n",
    "                component=component, frequencies=F_str,\n",
    "                scale=scale, realization=realization_str\n",
    "            ))\n",
    "            for scale in scales\n",
    "        ]\n",
    "\n",
    "        # 6) Compute weights (keep last one for a single final check)\n",
    "        weight_vector_load = []\n",
    "        W_for_final_check = None\n",
    "        for scale_idx, scale in enumerate(scales):\n",
    "            if constraint:\n",
    "                compute_weight_vector(\n",
    "                    R_covariance[scale_idx], scale, realization_str,\n",
    "                    output_templates['weight_vector_matrices'],\n",
    "                    component=component,\n",
    "                    component_name=component_name_tag,   # string for filenames\n",
    "                    constraint=True, F=F, f=f\n",
    "                )\n",
    "                name = f\"cilc_{component_name_tag}\"\n",
    "            else:\n",
    "                compute_weight_vector(\n",
    "                    R_covariance[scale_idx], scale, realization_str,\n",
    "                    output_templates['weight_vector_matrices'],\n",
    "                    component=component,\n",
    "                    component_name=component_name_tag,\n",
    "                    constraint=False, F=F\n",
    "                )\n",
    "                name = \"weight_vector\"\n",
    "\n",
    "            weight_vector_path = output_templates['weight_vector_matrices'].format(\n",
    "                component=component,\n",
    "                component_name=component_name_tag,\n",
    "                type=name,\n",
    "                scale=scale,\n",
    "                realization=realization_str\n",
    "            )\n",
    "            W = np.load(weight_vector_path)\n",
    "            # normalize shape for global case\n",
    "            if W.ndim == 2 and 1 in W.shape:\n",
    "                W = W.reshape(-1)\n",
    "\n",
    "            weight_vector_load.append(W)\n",
    "            W_for_final_check = W  # remember the last scale's weights\n",
    "\n",
    "        # 7) Create and save doubled ILC maps\n",
    "        doubled_maps = []\n",
    "        for i, scale in enumerate(scales):\n",
    "            map_ = create_doubled_ILC_map(\n",
    "                frequencies, scale, weight_vector_load[i], doubled_MW_wav_c_j,\n",
    "                realization_str, component=component,\n",
    "                constraint=constraint, component_name=component_name_tag\n",
    "            )\n",
    "            doubled_maps.append(map_)\n",
    "            np.save(output_templates['ilc_maps'].format(\n",
    "                component=component,\n",
    "                component_name=component_name_tag,\n",
    "                scale=scale,\n",
    "                realization=realization_str\n",
    "            ), map_)\n",
    "\n",
    "        # 8) Trim maps\n",
    "        trimmed_maps = [\n",
    "            trim_to_original(\n",
    "                doubled_maps[i], scales[i], realization_str,\n",
    "                component=component,\n",
    "                component_name=component_name_tag,\n",
    "                path_template=output_templates['trimmed_maps']\n",
    "            )\n",
    "            for i in range(len(scales))\n",
    "        ]\n",
    "\n",
    "        # 9) Synthesize final map\n",
    "        synthesized_map = synthesize_ILC_maps_generalised(\n",
    "            trimmed_maps, realization_str, output_templates, L_max, N_directions,\n",
    "            component_name=component_name_tag, component=component, constraint=constraint\n",
    "        )\n",
    "        synthesized_maps.append(synthesized_map)\n",
    "\n",
    "        # 10) ONE-TIME verification per realization (at the end)\n",
    "        if constraint and (W_for_final_check is not None):\n",
    "            # normalize shape: (1,Nf)/(Nf,1) -> (Nf,)\n",
    "            W1 = W_for_final_check\n",
    "            if W1.ndim == 2 and 1 in W1.shape:\n",
    "                W1 = W1.reshape(-1)\n",
    "        \n",
    "            # exact cILC check: F^T w == f\n",
    "            resp = np.tensordot(W1, F, axes=([-1], [0]))  # (..., N_comp)\n",
    "            ok = np.allclose(resp, f, atol=1e-6, rtol=0.0)\n",
    "            print(\"FINAL CHECK  F^T w == f  ->\", ok)\n",
    "            if not ok:\n",
    "                print(\"max |F^T w - f| =\", float(np.max(np.abs(resp - f))))\n",
    "\n",
    "\n",
    "    return synthesized_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fce1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (CMB): [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      " 0.33333333 0.33333333 0.33333333]\n",
      "b (tSZ): [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.18225885e-01\n",
      " -8.15581790e-02 -6.09521620e-04  1.75660570e-01  4.38851414e-01\n",
      "  8.69438516e-01]\n",
      "c (sync): [0.86775717 0.27183924 0.06948647 0.02611258 0.01107374 0.00549842\n",
      " 0.00524893 0.01690708 0.40880854]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Physical constants ---\n",
    "h = 6.62607015e-34       # Planck constant [J·s]\n",
    "k = 1.380649e-23         # Boltzmann constant [J/K]\n",
    "T_cmb = 2.7255           # CMB temperature [K]\n",
    "c = 299792458            # Speed of light [m/s]\n",
    "\n",
    "# --- Planck frequency channels in GHz ---\n",
    "frequencies = ['030', '044', '070', '100', '143', '217', '353', '545', '857']\n",
    "freqs_GHz = np.array([float(f) for f in frequencies])\n",
    "nu = freqs_GHz * 1e9     # Convert GHz to Hz\n",
    "x = h * nu / (k * T_cmb) # Dimensionless frequency\n",
    "\n",
    "# --- Unit conversion factor from thermodynamic to brightness temp ---\n",
    "g_nu = (x**2 * np.exp(x)) / (np.exp(x) - 1)**2\n",
    "\n",
    "# --- (a) CMB: constant across frequencies in thermodynamic units ---\n",
    "a = np.ones_like(nu)/ np.linalg.norm(np.ones_like(nu))\n",
    "\n",
    "# --- (b) tSZ: thermal SZ effect frequency dependence ---\n",
    "fx = x * ((np.exp(x) + 1) / (np.exp(x) - 1)) - 4\n",
    "# Zero out known nulls (no tSZ expected at these bands)\n",
    "no_tsz_freqs = {'030', '044', '070'}\n",
    "fx = np.array([fx[i] if frequencies[i] not in no_tsz_freqs else 0 for i in range(len(frequencies))])\n",
    "# Normalize in thermodynamic units\n",
    "b = fx / np.linalg.norm(fx)\n",
    "\n",
    "# --- (c) Synchrotron: assume power law with β_s = -3.1 in brightness temp ---\n",
    "beta_s = -3.1\n",
    "nu0 = 30e9  # reference frequency (30 GHz)\n",
    "T_sync_ant = (nu / nu0) ** beta_s\n",
    "# Convert synchrotron to thermodynamic temp\n",
    "T_sync_thermo = T_sync_ant / g_nu\n",
    "# Normalize\n",
    "c = T_sync_thermo / np.linalg.norm(T_sync_thermo)\n",
    "\n",
    "# --- Output ---\n",
    "print(\"a (CMB):\", a)\n",
    "print(\"b (tSZ):\", b)\n",
    "print(\"c (sync):\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82910264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing realization 0000 for targets: ['cmb', 'tsz']\n",
      "Processing realization 0000 for component CSNT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Frequency names\n",
    "frequencies = ['030', '044', '070', '100', '143', '217', '353', '545', '857']\n",
    "\n",
    "# Wavelet scales\n",
    "scales = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Realization list (strings)\n",
    "realizations = [\"0000\"]\n",
    "\n",
    "# Whether you're running constrained or unconstrained ILC\n",
    "constraint = True  # set False for unconstrained run\n",
    "\n",
    "# Output templates\n",
    "output_templates = {\n",
    "    'doubled_maps': \"ILC/wavelet_doubled/Wav_Pix2_F{frequency}_S{scale}_R{realization}_MP.npy\",\n",
    "    'covariance_matrices': \"ILC/covariance_matrix/cov_MW_Pix2_F{frequencies}_S{scale}_R{realization}_MP.npy\",\n",
    "    'weight_vector_matrices': \"ILC/weight_vector_data/{type}_S{scale}_R{realization}_MP.npy\",\n",
    "    'ilc_maps': \"ILC/ILC_doubled_maps/ILC_Map_S{scale}_R{realization}_MP.npy\",\n",
    "    'trimmed_maps': \"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S{scale}_R{realization}_MP.npy\",\n",
    "    'synthesized_maps': \"ILC/synthesized_ILC_MW_maps/ILC_MW_Map_R{realization}_MP.npy\",\n",
    "    'f_scal': \"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_F100_R{realization}.npy\"\n",
    "}\n",
    "\n",
    "output_templates_CONSTRAINT = {\n",
    "    'doubled_maps': \"ILC/wavelet_doubled/Wav_Pix2_{component}_F{frequency}_S{scale}_R{realization}_MP.npy\",\n",
    "    'covariance_matrices': \"ILC/covariance_matrix/cov_MW_Pix2_{component}_F{frequencies}_S{scale}_R{realization}_MP.npy\",\n",
    "    'weight_vector_matrices': \"ILC/weight_vector_data/{component}_cilc_{component_name}_S{scale}_R{realization}_MP.npy\",\n",
    "    'ilc_maps': \"ILC/ILC_doubled_maps/ILC_Map_{component}_cilc_{component_name}_S{scale}_R{realization}_MP.npy\",\n",
    "    'trimmed_maps': \"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_{component}_cilc_{component_name}_S{scale}_R{realization}_MP.npy\",\n",
    "    'synthesized_maps': \"ILC/synthesized_ILC_MW_maps/{component}_ILC_MW_Map_cilc_{component_name}_R{realization}_MP.npy\",\n",
    "    'f_scal': \"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_{component}_F100_R{realization}.npy\"\n",
    "}\n",
    "\n",
    "# Select templates\n",
    "templates = output_templates_CONSTRAINT if constraint else output_templates\n",
    "\n",
    "file_template = (\n",
    "    \"wavelet_transform/wavelets/wav_MW_maps/\"\n",
    "    \"Wav_MW_Pix_{component}_F{frequency}_S{scale}_R{realization}.npy\"\n",
    ")\n",
    "\n",
    "# ---- NEW: choose one or many target components here ----\n",
    "# Example A: sum-preserve CMB+tSZ\n",
    "target_components = [\"cmb\", \"tsz\"]\n",
    "# Example B: single CMB (uncomment to use)\n",
    "# target_components = \"cmb\"\n",
    "\n",
    "# For filenames: make a compact tag like \"cmb+tsz\" or \"cmb\"\n",
    "component_tag = \"+\".join(target_components) if isinstance(target_components, (list, tuple)) else target_components\n",
    "\n",
    "for realization in realizations:\n",
    "    print(f\"Processing realization {realization} for targets: {target_components}\")\n",
    "\n",
    "    constrained_maps = ILC_wav_coeff_maps_MP(\n",
    "        file_template=file_template,\n",
    "        frequencies=frequencies,\n",
    "        scales=scales,\n",
    "        realizations=[realization],\n",
    "        output_templates=templates,\n",
    "        L_max=64,\n",
    "        N_directions=1,\n",
    "        constraint=constraint,\n",
    "        F=F,\n",
    "        component='CSNT',\n",
    "        # ---- pass the list or string directly; your finder handles both ----\n",
    "        component_name=target_components,\n",
    "        # If your ILC function formats templates itself, it will substitute {component_name}\n",
    "        # Otherwise, you can pre-format paths using `component_tag` as needed.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65788dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Frequency names\n",
    "frequencies = ['030', '044', '070', '100', '143', '217', '353', '545', '857']\n",
    "\n",
    "# Wavelet scales\n",
    "scales = [0, 1, 2, 3, 4, 5, 6]  \n",
    "\n",
    "# Realization list\n",
    "realizations = [0]\n",
    "\n",
    "# Whether you're running constrained or unconstrained ILC\n",
    "constraint = True  # change this to False for unconstrained run\n",
    "\n",
    "# Define both output_templates versions\n",
    "output_templates = {\n",
    "    'doubled_maps': \"ILC/wavelet_doubled/Wav_Pix2_F{frequency}_S{scale}_R{realization}_MP.npy\",\n",
    "    'covariance_matrices': \"ILC/covariance_matrix/cov_MW_Pix2_F{frequencies}_S{scale}_R{realization}_MP.npy\",\n",
    "    'weight_vector_matrices': \"ILC/weight_vector_data/{type}_S{scale}_R{realization}_MP.npy\",\n",
    "    'ilc_maps': \"ILC/ILC_doubled_maps/ILC_Map_S{scale}_R{realization}_MP.npy\",\n",
    "    'trimmed_maps': \"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_S{scale}_R{realization}_MP.npy\",\n",
    "    'synthesized_maps': \"ILC/synthesized_ILC_MW_maps/ILC_MW_Map_R{realization}_MP.npy\",\n",
    "    'f_scal': \"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_F100_R{realization}.npy\"\n",
    "}\n",
    "\n",
    "output_templates_CONSTRAINT = {\n",
    "    'doubled_maps': \"ILC/wavelet_doubled/Wav_Pix2_{component}_F{frequency}_S{scale}_R{realization}_MP.npy\",\n",
    "    'covariance_matrices': \"ILC/covariance_matrix/cov_MW_Pix2_{component}_F{frequencies}_S{scale}_R{realization}_MP.npy\",\n",
    "    'weight_vector_matrices': \"ILC/weight_vector_data/{component}_cilc_{component_name}_S{scale}_R{realization}_MP.npy\",\n",
    "    'ilc_maps': \"ILC/ILC_doubled_maps/ILC_Map_{component}_cilc_{component_name}_S{scale}_R{realization}_MP.npy\",\n",
    "    'trimmed_maps': \"ILC/ILC_processed_wavelet_maps/ILC_processed_wav_Map_{component}_cilc_{component_name}_S{scale}_R{realization}_MP.npy\",\n",
    "    'synthesized_maps': \"ILC/synthesized_ILC_MW_maps/{component}_ILC_MW_Map_cilc_{component_name}_R{realization}_MP.npy\",\n",
    "    'f_scal': \"wavelet_transform/wavelets/scal_coeffs/Scal_MW_Pix_{component}_F100_R{realization}.npy\"\n",
    "}\n",
    "\n",
    "\n",
    "# Select appropriate output template based on constraint flag\n",
    "templates = output_templates_CONSTRAINT if constraint else output_templates\n",
    "\n",
    "file_template = (\n",
    "    \"wavelet_transform/wavelets/wav_MW_maps/\"\n",
    "    \"Wav_MW_Pix_{component}_F{frequency}_S{scale}_R{realization}.npy\"\n",
    ")\n",
    "\n",
    "realizations = [\"0000\"]  # string\n",
    "\n",
    "for realization in realizations:\n",
    "    print(f\"Processing realization {realization}\")\n",
    "\n",
    "    constrained_maps = ILC_wav_coeff_maps_MP(\n",
    "        file_template=file_template,\n",
    "        frequencies=frequencies,\n",
    "        scales=scales,\n",
    "        realizations=[realization],  # string\n",
    "        output_templates=templates,\n",
    "        L_max=64,\n",
    "        N_directions=1,\n",
    "        constraint=True,\n",
    "        F=F,\n",
    "        component='CSNT',\n",
    "        component_name='cmb'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_cmb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
